# VertaAI Product Guide

**Version:** 3.0
**Last Updated:** February 14, 2026
**Audience:** New developers, customers, and technical stakeholders

**Major Update:** This version reflects the strategic pivot to **Contract Integrity & Readiness**, introducing a dual-track architecture with fast contract validation (Track 1) and thorough drift remediation (Track 2).

---

## Table of Contents

1. [What is VertaAI?](#what-is-vertaai)
2. [The Problem We Solve](#the-problem-we-solve)
3. [How VertaAI Works](#how-vertaai-works)
4. [Why Not Build It Yourself?](#why-not-build-it-yourself)
5. [Technical Architecture](#technical-architecture)
6. [State Machine & Processing Flow](#state-machine--processing-flow)
7. [Input Sources & Output Targets](#input-sources--output-targets)
8. [User Onboarding & Setup](#user-onboarding--setup)
9. [Integration Compatibility Matrix](#integration-compatibility-matrix)
10. [Key Technical Concepts](#key-technical-concepts)
11. [Example Workflows](#example-workflows)
12. [FAQ](#faq)

---

## What is VertaAI?

**VertaAI** is an **AI-powered governance platform** that ensures consistency across your entire operational stack â€” from code to APIs to documentation to infrastructure to observability.

### One-Liner
> "We prevent inconsistencies across code â†” API â†” docs â†” runbooks â†” dashboards â†” diagrams by validating contracts in real-time and proposing surgical fixes when drift occurs."

### Core Value Proposition
VertaAI operates on two levels:

1. **Contract Integrity & Readiness** (Prevention): Fast, deterministic validation that catches inconsistencies before they reach production. When you open a PR, VertaAI validates that your OpenAPI spec matches your documentation, your Terraform matches your runbooks, and your dashboards match your alerts â€” all in < 30 seconds.

2. **Drift Detection & Remediation** (Correction): When changes slip through or accumulate over time, VertaAI detects the drift between what your documentation says and what actually happens, then proposes precise, evidence-grounded fixes for human approval.

---

## The Problem We Solve

### The Contract Integrity Problem

Every engineering team faces this cycle:

```
Code Changes â†’ API Drifts â†’ Docs Become Stale â†’ Runbooks Lie â†’ Dashboards Mislead â†’ Incidents Happen â†’ (Maybe) Fixed
```

**Specific pain points:**

1. **API â†” Docs Drift**: OpenAPI spec says endpoint requires `userId`, docs say it's optional
2. **Infrastructure â†” Runbook Drift**: Terraform deploys to 3 regions, runbook only covers 2
3. **Dashboard â†” Alert Drift**: Grafana dashboard shows metric `api_latency_p99`, but alerts use `api_response_time_p99`
4. **Code â†” Ownership Drift**: CODEOWNERS says `@platform-team`, but team was renamed to `@infra-team`
5. **Deployment â†” Docs Drift**: Switched from kubectl to Helm, runbook still shows kubectl commands
6. **Missing Coverage**: New failure modes, rollback procedures, or edge cases aren't documented

### Why Traditional Solutions Fail

| Approach | Why It Fails |
|----------|--------------|
| **Manual updates** | Humans forget, especially during incidents |
| **Linters** | Can't detect semantic drift (wrong commands that are syntactically valid) |
| **Search tools** | Help you find docs, don't keep them correct |
| **Wikis with "last updated"** | Timestamp doesn't mean content is accurate |
| **"Living documentation"** | Requires discipline that doesn't scale |
| **Contract testing** | Only validates code â†” API, ignores docs/runbooks/dashboards |
| **Schema validation** | Catches syntax errors, not semantic inconsistencies |

---

## How VertaAI Works

### The VertaAI Dual-Track Approach

VertaAI operates on two parallel tracks:

#### **Track 1: Contract Validation (Fast, Deterministic, PR-Blocking)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. PR OPENED/UPDATED (GitHub Webhook)                           â”‚
â”‚  â”œâ”€ Extract changed files (OpenAPI, Terraform, CODEOWNERS, etc.) â”‚
â”‚  â”œâ”€ Resolve applicable contracts (file patterns, service tags)   â”‚
â”‚  â””â”€ Trigger contract validation (< 30s total)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. FETCH ARTIFACT SNAPSHOTS (Parallel)                          â”‚
â”‚  â”œâ”€ Primary artifacts (OpenAPI spec, Terraform configs)          â”‚
â”‚  â”œâ”€ Secondary artifacts (Confluence docs, Notion pages)          â”‚
â”‚  â””â”€ Reference artifacts (Grafana dashboards, alert configs)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. RUN COMPARATORS (Deterministic, < 5s each)                   â”‚
â”‚  â”œâ”€ OpenAPI â†” Docs: Endpoint/schema/example parity              â”‚
â”‚  â”œâ”€ Terraform â†” Runbook: Infrastructure consistency             â”‚
â”‚  â”œâ”€ Dashboard â†” Alert: Metric name consistency                  â”‚
â”‚  â””â”€ CODEOWNERS â†” Docs: Ownership accuracy                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. GENERATE INTEGRITY FINDINGS (Structured)                     â”‚
â”‚  â”œâ”€ Severity: critical/high/medium/low                           â”‚
â”‚  â”œâ”€ Drift type: endpoint_missing, schema_mismatch, etc.          â”‚
â”‚  â”œâ”€ Evidence: Specific mismatches with pointers                  â”‚
â”‚  â””â”€ Recommended action: block_merge/create_patch/notify         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. CREATE GITHUB CHECK (Real-time)                              â”‚
â”‚  â”œâ”€ Conclusion: success (PASS) / neutral (WARN) / failure (BLOCK)â”‚
â”‚  â”œâ”€ Summary: Risk tier, findings count, impact band              â”‚
â”‚  â”œâ”€ Annotations: File-level findings (max 50)                    â”‚
â”‚  â””â”€ Details: Evidence, recommendations, links                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. (OPTIONAL) CREATE DRIFT CANDIDATE                            â”‚
â”‚  â””â”€ If findings are severe â†’ Trigger remediation track          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Track 2: Drift Remediation (Thorough, LLM-Assisted, Human-Approved)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DETECT DRIFT (Deterministic)                                 â”‚
â”‚  â”œâ”€ GitHub PR merged (changed deployment scripts)                â”‚
â”‚  â”œâ”€ PagerDuty incident resolved (new failure scenario)           â”‚
â”‚  â”œâ”€ Contract validation findings (from Track 1)                  â”‚
â”‚  â””â”€ Slack questions clustered (knowledge gap detected)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ANALYZE & CLASSIFY (Deterministic Comparison + Typed Deltas) â”‚
â”‚  â”œâ”€ Extract artifacts from source (commands, URLs, steps)        â”‚
â”‚  â”œâ”€ Extract artifacts from docs (current state)                  â”‚
â”‚  â”œâ”€ Bounded context expansion: fetch up to 3 key changed files   â”‚
â”‚  â”œâ”€ Compare artifacts with typed deltas (key:value, not just     â”‚
â”‚  â”‚   key presence; tool replacement; version mismatch)           â”‚
â”‚  â”œâ”€ Detect coverage gaps (orthogonal dimension)                  â”‚
â”‚  â””â”€ Confidence score (0-100%) based on artifact overlap          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. THRESHOLD ROUTING + MATERIALITY GATE                         â”‚
â”‚  â”œâ”€ Check confidence against ignore threshold                    â”‚
â”‚  â”œâ”€ If below threshold â†’ Skip patch generation (save LLM calls)  â”‚
â”‚  â”œâ”€ Materiality gate: skip low-value patches deterministically   â”‚
â”‚  â”‚   (e.g., single low-confidence delta, missing managed region) â”‚
â”‚  â”œâ”€ Check temporal drift accumulation (bundle small drifts)      â”‚
â”‚  â””â”€ If above threshold + material â†’ Continue to patch generation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. GENERATE PATCH (Evidence-Grounded, NOT Full Rewrite)         â”‚
â”‚  â”œâ”€ LLM receives typed deltas from EvidenceBundle (not raw diff) â”‚
â”‚  â”œâ”€ Structured evidence contract: deltas, impact band, drift     â”‚
â”‚  â”‚   type, consequence text, fired rules                         â”‚
â”‚  â”œâ”€ Truncation priority: critical/high deltas included first     â”‚
â”‚  â”œâ”€ Generate unified diff (like a PR)                            â”‚
â”‚  â””â”€ Add summary and sources                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ROUTE TO RIGHT OWNER & CLUSTER (OPT-IN)                      â”‚
â”‚  â”œâ”€ Check CODEOWNERS file                                        â”‚
â”‚  â”œâ”€ Check doc ownership mappings                                 â”‚
â”‚  â”œâ”€ Check PagerDuty on-call                                      â”‚
â”‚  â”œâ”€ If clustering enabled â†’ Group similar drifts                 â”‚
â”‚  â””â”€ Fallback to team default                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. SEND TO SLACK FOR APPROVAL                                   â”‚
â”‚  â”œâ”€ Individual: Show diff preview (12 lines)                     â”‚
â”‚  â”œâ”€ Cluster: Show aggregated summary + bulk actions              â”‚
â”‚  â”œâ”€ Include confidence score and coverage gap indicator          â”‚
â”‚  â”œâ”€ Link to source (PR, incident, etc.)                          â”‚
â”‚  â””â”€ Buttons: [Approve] [Edit] [Reject] [Snooze]                 â”‚
â”‚  â””â”€ Cluster: [Approve All] [Review Individually] [Reject All]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. HUMAN DECISION                                               â”‚
â”‚  â”œâ”€ Approve â†’ Update doc immediately (Confluence/Notion)         â”‚
â”‚  â”œâ”€ Edit â†’ Modify diff â†’ Re-approve                              â”‚
â”‚  â”œâ”€ Reject â†’ Learn from feedback (audit trail)                   â”‚
â”‚  â””â”€ Snooze â†’ Remind in 24 hours (re-queue)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Differentiators

#### **Contract Validation (Track 1)**
1. **Fast, deterministic validation**: < 30s total for PR checks (no LLM calls)
2. **Contract-first design**: Explicit contract definitions with artifact roles (primary/secondary/reference)
3. **Pluggable comparators**: Easy to add new comparator types (OpenAPI, Terraform, Grafana, etc.)
4. **Structured findings**: Machine-readable IntegrityFindings with severity, evidence, and recommendations
5. **Real-time GitHub Checks**: Inline annotations on changed files with actionable feedback
6. **Snapshot versioning**: Immutable artifact snapshots with TTL cleanup
7. **Multi-artifact comparison**: Compare across 3+ artifact types in a single contract
8. **Confidence scoring**: Resolution confidence (0.0-1.0) based on matching strategy

#### **Drift Remediation (Track 2)**
9. **Deterministic detection with typed deltas**: 100% reproducible artifact comparison producing machine-readable typed deltas (no LLM randomness)
10. **Evidence-grounded patching**: LLM agents receive structured typed deltas from the EvidenceBundle â€” not raw diffs â€” ensuring every patch element traces to deterministic evidence
11. **Materiality gate**: Deterministic pre-patch filter prevents low-value patches (tag-only changes, low-confidence single deltas) from reaching the LLM
12. **Bounded context expansion**: Fetches up to 3 key changed files (config, Dockerfile, API specs) to distinguish critical changes from trivial edits
13. **Temporal drift accumulation**: Tracks cumulative drift per document over time, bundling multiple small drifts into comprehensive updates
14. **Cluster-first triage**: Groups similar drifts for bulk actions (80-90% notification reduction)
15. **Orthogonal coverage**: Detects both incorrect AND missing documentation
16. **Early threshold routing**: Filters low-confidence drifts before patch generation (30-40% LLM call reduction)
17. **Diff-based, not rewrites**: We propose surgical changes, not full document regeneration
18. **Human-in-the-loop**: No autonomous publishing â€” you always approve
19. **Multi-source correlation**: Combines GitHub + PagerDuty + Slack + Contract findings
20. **Ownership-aware**: Routes to the right person based on CODEOWNERS, mappings, on-call
21. **Complete audit trail**: Full observability with PlanRun tracking, EvidenceBundle pattern, and materiality skip reasons

#### **Cross-Cutting**
22. **Agent PR gatekeeper**: Detects agent-authored PRs and gates risky changes with evidence-based checks
23. **Delta sync findings**: Reuses existing parsers (IaC, OpenAPI, CODEOWNERS) to detect drift in real-time
24. **Workspace-scoped multi-tenancy**: Complete data isolation with composite primary keys

---

## Why Not Build It Yourself?

### Option 1: Deterministic Rules

**What you'd build:**
```python
if "kubectl" in pr_diff and "helm" in pr_diff:
    update_doc("deployment.md", old="kubectl", new="helm")
```

**Why it fails:**
- âŒ Can't handle semantic changes ("deploy to staging first" â†’ "deploy to prod directly")
- âŒ Brittle - breaks when doc structure changes
- âŒ Can't understand context (is this kubectlâ†’helm migration or just adding helm?)
- âŒ Requires maintaining hundreds of rules
- âŒ No confidence scoring
- âŒ Can't handle ambiguity

### Option 2: Pure LLM Solution

**What you'd build:**
```python
prompt = f"Update this doc based on this PR: {pr_diff}"
new_doc = llm.generate(prompt)
```

**Why it fails:**
- âŒ Hallucinations - LLM invents commands/URLs that don't exist
- âŒ Scope creep - rewrites entire sections unnecessarily
- âŒ No version control - can't track what changed
- âŒ No evidence trail - can't explain why it made changes
- âŒ Expensive - processes entire doc every time
- âŒ No approval workflow

### VertaAI's Hybrid Approach

```
Deterministic Rules + LLM + Human Approval = Reliable Automation
```

| Component | Role | Why It Matters |
|-----------|------|----------------|
| **Deterministic baseline checks** | Find exact matches (old tool names, URLs) | Fast, accurate, explainable |
| **LLM classification** | Understand semantic drift | Handles nuance and context |
| **Diff generation** | Surgical changes only | Reviewable, version-controlled |
| **Validation layer** | Block unsafe changes | Prevents secrets, scope violations |
| **Human approval** | Final decision | Trust and accountability |

**Example:**
```
Signal: PR changes "kubectl apply" to "helm install"
â”œâ”€ Baseline check: Finds "kubectl" in deployment runbook âœ“
â”œâ”€ LLM classification: "instruction drift" (tool migration) âœ“
â”œâ”€ LLM diff generation: Proposes specific line changes âœ“
â”œâ”€ Validator: Checks diff applies cleanly, no secrets âœ“
â”œâ”€ Owner routing: Sends to @platform-team (from CODEOWNERS) âœ“
â””â”€ Human: Reviews diff in Slack, clicks "Approve" âœ“
```

---

## Technical Architecture

### System Overview

VertaAI is built as a **multi-tenant, event-driven system** with **two parallel processing tracks**: fast contract validation and thorough drift remediation.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VERTAAI ARCHITECTURE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                    INPUT LAYER (Webhooks)                           â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚     â”‚
â”‚  â”‚  â”‚   GitHub     â”‚  â”‚  PagerDuty   â”‚  â”‚    Slack     â”‚              â”‚     â”‚
â”‚  â”‚  â”‚   Webhook    â”‚  â”‚   Webhook    â”‚  â”‚   Events     â”‚              â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â”‚                  â”‚                  â”‚                           â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                               â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              SIGNAL NORMALIZATION & STORAGE                          â”‚     â”‚
â”‚  â”‚  â€¢ SignalEvent table (workspace-scoped)                              â”‚     â”‚
â”‚  â”‚  â€¢ Extract: repo, service, author, diff, metadata                    â”‚     â”‚
â”‚  â”‚  â€¢ Dual routing: Contract validation + Drift detection               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                               â”‚                                              â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚            â–¼                  â–¼                  â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ CONTRACT         â”‚  â”‚ AGENT PR        â”‚  â”‚ STATE MACHINE           â”‚     â”‚
â”‚  â”‚ VALIDATION       â”‚  â”‚ GATEKEEPER      â”‚  â”‚ ORCHESTRATOR            â”‚     â”‚
â”‚  â”‚ â€¢ Resolver       â”‚  â”‚ â€¢ Agent Detect  â”‚  â”‚ â€¢ QStash job queue      â”‚     â”‚
â”‚  â”‚ â€¢ Fetcher        â”‚  â”‚ â€¢ Risk Scoring  â”‚  â”‚ â€¢ Bounded loop (5 max)  â”‚     â”‚
â”‚  â”‚ â€¢ Comparators    â”‚  â”‚ â€¢ Delta Sync    â”‚  â”‚ â€¢ Distributed locking   â”‚     â”‚
â”‚  â”‚ â€¢ Findings       â”‚  â”‚ â€¢ GitHub Checks â”‚  â”‚ â€¢ Retry w/ backoff      â”‚     â”‚
â”‚  â”‚ â€¢ GitHub Check   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚                     â”‚
â”‚           â”‚                                           â”‚                     â”‚
â”‚           â–¼                                           â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ GitHub Check API â”‚         â–¼         â–¼                         â–¼         â”‚
â”‚  â”‚ â€¢ PASS/WARN/BLOCKâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Annotations    â”‚  â”‚ LLM AGENTS  â”‚      â”‚ DOC SERVICE â”‚  â”‚ SLACK APPâ”‚  â”‚
â”‚  â”‚ â€¢ Findings       â”‚  â”‚             â”‚      â”‚             â”‚  â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ Triage    â”‚      â”‚ â€¢ Adapters  â”‚  â”‚ â€¢ Composeâ”‚  â”‚
â”‚                        â”‚ â€¢ Planner   â”‚      â”‚ â€¢ Fetch     â”‚  â”‚ â€¢ Buttonsâ”‚  â”‚
â”‚                        â”‚ â€¢ Generator â”‚      â”‚ â€¢ Writeback â”‚  â”‚ â€¢ Routingâ”‚  â”‚
â”‚                        â”‚ (Stateless) â”‚      â”‚ â€¢ Versioningâ”‚  â”‚          â”‚  â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                               â”‚                                              â”‚
â”‚                               â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                    DATABASE (PostgreSQL)                             â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚     â”‚
â”‚  â”‚  â”‚  Workspace   â”‚  â”‚ SignalEvent  â”‚  â”‚DriftCandidateâ”‚               â”‚     â”‚
â”‚  â”‚  â”‚ (tenant)     â”‚  â”‚ (normalized) â”‚  â”‚ (state)      â”‚               â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚     â”‚
â”‚  â”‚  â”‚ContractPack  â”‚  â”‚ArtifactSnap  â”‚  â”‚IntegrityFind â”‚               â”‚     â”‚
â”‚  â”‚  â”‚ (contracts)  â”‚  â”‚ (versioned)  â”‚  â”‚ (findings)   â”‚               â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚     â”‚
â”‚  â”‚  â”‚PatchProposal â”‚  â”‚ Integration  â”‚  â”‚DocMappingsV2 â”‚               â”‚     â”‚
â”‚  â”‚  â”‚ (diff)       â”‚  â”‚ (OAuth)      â”‚  â”‚ (routing)    â”‚               â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Layer | Technology | Deployment | Purpose |
|-------|------------|------------|---------|
| **Frontend** | Next.js 14 (React) | Vercel | Admin UI, onboarding |
| **Backend API** | Node.js + Express | Railway | Webhooks, state machine |
| **Database** | PostgreSQL 15 | Railway | Workspace data, state |
| **Job Queue** | QStash (Upstash) | Cloud | Async state transitions |
| **LLM** | Claude Sonnet 4 | Anthropic API | Classification, generation |
| **Auth** | Slack OAuth | - | Primary auth method |

### Key Architectural Patterns

#### 1. Multi-Tenant Workspace Model

Every entity is scoped to a `workspaceId`:

```typescript
// Composite primary key pattern
model DriftCandidate {
  workspaceId String
  id          String
  @@id([workspaceId, id])
}

model ContractPack {
  workspaceId String
  id          String
  @@id([workspaceId, id])
}
```

**Why:** Ensures complete data isolation between customers.

#### 2. Contract-First Design

Contracts are first-class objects that define what should be consistent:

```typescript
model ContractPack {
  workspaceId     String
  id              String
  name            String
  description     String
  invariants      Invariant[]  // What to check
  scope           Json         // Where to apply (repos, services, file patterns)
  isActive        Boolean
  @@id([workspaceId, id])
}

model Invariant {
  invariantId       String
  comparatorType    String      // 'openapi_docs_endpoint_parity', 'terraform_runbook_consistency'
  artifactRoles     Json        // { primary: 'openapi', secondary: 'confluence_page' }
  expectedOutcome   String      // 'all_endpoints_documented', 'infrastructure_matches_runbook'
}
```

**Why:** Explicit, versioned contracts that can be audited and evolved.

#### 3. Deterministic State Machine (Drift Remediation)

18 states with explicit transition handlers:

```typescript
const TRANSITION_HANDLERS: Record<DriftState, TransitionHandler> = {
  [DriftState.INGESTED]: handleIngested,
  [DriftState.ELIGIBILITY_CHECKED]: handleEligibilityChecked,
  // ... 16 more states
};
```

**Why:** Predictable, debuggable, resumable processing.

#### 4. Adapter Pattern for Artifacts & Documentation

Unified interface for different systems:

```typescript
interface ArtifactAdapter {
  fetch(ref: ArtifactRef): Promise<FetchResult>;
  getArtifactUrl(ref: ArtifactRef): string;
}

interface DocAdapter {
  fetch(doc: DocRef): Promise<FetchResult>;
  writePatch(params: WritePatchParams): Promise<WriteResult>;
  supportsDirectWriteback(): boolean;
  getDocUrl(docId: string): string;
}
```

**Why:** Easy to add new systems (Grafana, Datadog, etc.) without changing core logic.

#### 5. Comparator Pattern (Template Method)

Pluggable, stateless comparators:

```typescript
abstract class BaseComparator implements IComparator {
  async compare(input: ComparatorInput): Promise<ComparatorResult> {
    this.validateInput(input);
    if (!this.canCompare(input.invariant, [input.leftSnapshot, input.rightSnapshot])) {
      return this.createSkippedResult(input.invariant.invariantId, 'not_applicable');
    }
    const leftData = this.extractData(input.leftSnapshot);
    const rightData = this.extractData(input.rightSnapshot);
    const findings = await this.performComparison(leftData, rightData, input);
    return { invariantId: input.invariant.invariantId, evaluated: true, findings };
  }

  abstract canCompare(invariant: Invariant, snapshots: ArtifactSnapshot[]): boolean;
  abstract extractData(snapshot: ArtifactSnapshot): any;
  abstract performComparison(left: any, right: any, input: ComparatorInput): Promise<IntegrityFinding[]>;
}
```

**Why:** Consistent workflow, easy to test, pluggable implementations.

#### 6. Bounded Loop Pattern

```typescript
const MAX_TRANSITIONS_PER_INVOCATION = 5;
```

**Why:** Prevents infinite loops, keeps job execution time predictable.

#### 7. Evidence-Based Patch Generation

```typescript
interface EvidencePack {
  toolMigrations: ToolMigration[];  // kubectl â†’ helm
  scenarioKeywords: string[];       // "rollback", "incident"
  ownershipChanges: OwnerChange[];  // team moves
}
```

**Why:** Every change is traceable to a real signal.

---

## State Machine & Processing Flow

### The 18-State Pipeline

VertaAI uses a **deterministic state machine** to process every drift candidate. Each state has a single responsibility and explicit transition logic.

```
INGESTED
  â†“
ELIGIBILITY_CHECKED â”€â”€â”€â”€â†’ (filtered out if noise)
  â†“
SIGNALS_CORRELATED â”€â”€â”€â”€â”€â†’ (join signals + check temporal drift accumulation)
  â†“
DOCS_RESOLVED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (deterministic doc targeting, no LLM)
  â†“
DOCS_FETCHED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (fetch doc content + bounded context expansion: up to 3 key files)
  â†“
DOC_CONTEXT_EXTRACTED â”€â”€â†’ (extract relevant sections)
  â†“
EVIDENCE_EXTRACTED â”€â”€â”€â”€â”€â†’ (deterministic comparison with typed deltas: key:value, tool
                           replacement, version mismatch, coverage gap)
  â†“
BASELINE_CHECKED â”€â”€â”€â”€â”€â”€â”€â†’ (build EvidenceBundle + early threshold routing + materiality gate)
  â†“                        â”œâ”€ Below threshold â†’ COMPLETED
  â†“                        â””â”€ Not material â†’ COMPLETED (skip reason persisted for temporal tracking)
PATCH_PLANNED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (LLM receives typed deltas from EvidenceBundle, not raw diff)
  â†“
PATCH_GENERATED â”€â”€â”€â”€â”€â”€â”€â”€â†’ (LLM: generate unified diff, evidence-grounded)
  â†“
PATCH_VALIDATED â”€â”€â”€â”€â”€â”€â”€â”€â†’ (code validation: secrets, size, scope)
  â†“
OWNER_RESOLVED â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (clustering: group similar drifts if enabled)
  â†“
SLACK_SENT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (send individual or cluster notification)
  â†“
AWAITING_HUMAN â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (wait for button click)
  â†“
  â”œâ”€ APPROVED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ WRITEBACK_VALIDATED â†’ WRITTEN_BACK â†’ COMPLETED
  â”œâ”€ EDIT_REQUESTED â”€â”€â”€â”€â†’ (back to PATCH_GENERATED)
  â”œâ”€ REJECTED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ COMPLETED (with audit trail)
  â””â”€ SNOOZED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ AWAITING_HUMAN (re-queue after delay)
```

### State Descriptions

| State | What Happens | Exit Conditions |
|-------|--------------|-----------------|
| **INGESTED** | Signal received from webhook | Always â†’ ELIGIBILITY_CHECKED |
| **ELIGIBILITY_CHECKED** | Apply noise filters (file paths, labels, size) | Pass â†’ SIGNALS_CORRELATED<br>Fail â†’ COMPLETED |
| **SIGNALS_CORRELATED** | Join multiple signals for same drift (dedup). Check temporal drift accumulation: has this doc accumulated N small drifts that should be bundled into a comprehensive update? | Always â†’ DOCS_RESOLVED |
| **DOCS_RESOLVED** | Deterministic doc targeting (no LLM) | Found â†’ DOCS_FETCHED<br>Not found â†’ FAILED_NEEDS_MAPPING |
| **DOCS_FETCHED** | Fetch current doc content via adapter. **Bounded context expansion**: also fetch up to 3 key changed files (`*.yaml`, `*.conf`, `Dockerfile`, `*.tf`, `openapi.*`, `CODEOWNERS`) with a 30K char budget for richer artifact extraction | Success â†’ DOC_CONTEXT_EXTRACTED<br>Error â†’ FAILED |
| **DOC_CONTEXT_EXTRACTED** | Extract relevant sections (deployment, rollback, etc.) | Always â†’ EVIDENCE_EXTRACTED |
| **EVIDENCE_EXTRACTED** | Deterministic comparison with **typed deltas**: extract artifacts from source + doc (with file context when available), compare using key:value matching, tool replacement detection, version mismatch detection. Output: `TypedDelta[]` with `{artifactType, action, sourceValue, docValue, confidence}` | Always â†’ BASELINE_CHECKED |
| **BASELINE_CHECKED** | Build EvidenceBundle with typed deltas. Early threshold routing filters low-confidence drifts. **Materiality gate**: deterministic rules skip low-value patches (e.g., `impactBand=low` + single delta, managed region missing + non-additive change). Skip reasons persisted for temporal tracking | Above threshold + material â†’ PATCH_PLANNED<br>Below threshold â†’ COMPLETED<br>Not material â†’ COMPLETED (skip reason stored) |
| **PATCH_PLANNED** | LLM receives structured typed deltas from EvidenceBundle (not raw diff). Evidence contract includes: deltas, impact band, drift type, consequence text, fired rules. Truncation priority: critical/high deltas first | Success â†’ PATCH_GENERATED<br>Uncertain â†’ COMPLETED |
| **PATCH_GENERATED** | LLM generates unified diff | Success â†’ PATCH_VALIDATED<br>Error â†’ FAILED |
| **PATCH_VALIDATED** | Validate diff (no secrets, size < 120 lines, applies cleanly) | Valid â†’ OWNER_RESOLVED<br>Invalid â†’ FAILED |
| **OWNER_RESOLVED** | Determine owner + clustering (if enabled, group similar drifts) | Always â†’ SLACK_SENT |
| **SLACK_SENT** | Send individual or cluster Slack notification | Always â†’ AWAITING_HUMAN |
| **AWAITING_HUMAN** | Wait for user action (approve/reject/snooze/edit) | (see human actions below) |
| **APPROVED** | User clicked "Approve" | Always â†’ WRITEBACK_VALIDATED |
| **REJECTED** | User clicked "Reject" | Creates audit event â†’ COMPLETED |
| **SNOOZED** | User clicked "Snooze" | Check expiry â†’ OWNER_RESOLVED (if expired)<br>Still snoozed â†’ SNOOZED |
| **WRITEBACK_VALIDATED** | Check doc version hasn't changed | Valid â†’ WRITTEN_BACK<br>Conflict â†’ FAILED |
| **WRITTEN_BACK** | Apply diff to doc via adapter | Success â†’ COMPLETED<br>Error â†’ FAILED |
| **COMPLETED** | Terminal state (success or rejected) | - |
| **FAILED** | Terminal state (error) | - |

### Bounded Loop Execution

To prevent infinite loops and keep job execution predictable:

```typescript
const MAX_TRANSITIONS_PER_INVOCATION = 5;

// Example execution:
Job 1: INGESTED â†’ ELIGIBILITY_CHECKED â†’ SIGNALS_CORRELATED â†’ DRIFT_CLASSIFIED â†’ DOCS_RESOLVED
       (5 transitions, stop and enqueue next job)

Job 2: DOCS_RESOLVED â†’ DOCS_FETCHED â†’ DOC_CONTEXT_EXTRACTED â†’ EVIDENCE_EXTRACTED â†’ BASELINE_CHECKED
       (5 transitions, stop and enqueue next job)

Job 3: BASELINE_CHECKED â†’ PATCH_PLANNED â†’ PATCH_GENERATED â†’ PATCH_VALIDATED â†’ OWNER_RESOLVED
       (5 transitions, stop and enqueue next job)

Job 4: OWNER_RESOLVED â†’ SLACK_SENT â†’ AWAITING_HUMAN
       (3 transitions, stop - human gate reached)
```

### Error Handling & Retries

```typescript
// Retryable errors (exponential backoff)
- TIMEOUT
- RATE_LIMITED
- SERVICE_UNAVAILABLE

// Non-retryable errors (immediate failure)
- NEEDS_DOC_MAPPING
- PATCH_VALIDATION_FAILED
- SECRETS_DETECTED
- DOC_NOT_FOUND

// Max retries: 3 attempts
// After 3 failures â†’ state = FAILED, error code stored
```

### Distributed Locking

```typescript
// Prevent concurrent processing of same drift
const LOCK_TTL_SECONDS = 30;

// Lock key: `drift:${workspaceId}:${driftId}`
// Acquired before state transition, released after
```

---

## Input Sources & Output Targets

### Input Sources (Signals)

VertaAI listens to multiple signal sources to detect documentation drift:

| Source | Status | What It Detects | Webhook Endpoint |
|--------|--------|-----------------|------------------|
| **GitHub PRs** | âœ… Live | Code/config changes that invalidate docs + Agent PR gatekeeper | `POST /webhooks/github/:workspaceId` |
| **PagerDuty Incidents** | âœ… Live | New failure scenarios, ownership changes | `POST /webhooks/pagerduty/:workspaceId` |
| **Slack Questions** | ğŸš§ Planned | Clustered questions revealing knowledge gaps | `POST /webhooks/slack/:workspaceId` |
| **Datadog/Grafana Alerts** | ğŸš§ Planned | Environment/tooling drift | TBD |

#### GitHub PR Signal

**Trigger conditions:**
- PR is **merged** (not just opened)
- Touches operational paths: `**/deploy/**`, `**/infra/**`, `**/terraform/**`, `**/helm/**`, `**/k8s/**`, `**/.github/workflows/**`, `**/config/**`
- OR contains keywords: `breaking`, `migrate`, `deprecate`, `rollback`, `deploy`, `helm`, `k8s`, `terraform`, `config`, `endpoint`, `auth`

**Dual Processing:**
1. **Drift Detection Pipeline**: Analyzes merged PRs for documentation drift
2. **Agent PR Gatekeeper**: Runs on all PRs (opened/synchronized) to detect agent-authored PRs and gate risky changes

**Extracted data:**
```typescript
{
  repo: "acme/api-service",
  service: "api-service",
  author: "alice",
  prNumber: 1234,
  title: "Migrate deployment from kubectl to helm",
  changedFiles: ["deploy/k8s/deployment.yaml", "docs/runbook.md"],
  diffExcerpt: "- kubectl apply -f deployment.yaml\n+ helm install api-service ./chart",
  mergedAt: "2026-02-07T10:30:00Z"
}
```

#### PagerDuty Incident Signal

**Trigger conditions:**
- Incident is **resolved** (not triggered/acknowledged)
- Incident has notes or resolution details

**Extracted data:**
```typescript
{
  incidentId: "Q1234567",
  service: "api-service",
  title: "API Gateway 503 errors",
  urgency: "high",
  resolvedBy: "bob",
  resolvedAt: "2026-02-07T11:00:00Z",
  notes: "Root cause: Redis connection pool exhausted. Fixed by increasing pool size.",
  impactedUsers: 1500
}
```

### Output Targets (Documentation Systems & GitHub Checks)

VertaAI supports multiple documentation platforms with two update strategies, plus GitHub Checks for PR gating:

| Doc System | Direct Writeback? | Update Method | Adapter |
|------------|-------------------|---------------|---------|
| **Confluence** | âœ… Yes | API call (immediate) | `confluenceAdapter.ts` |
| **Notion** | âœ… Yes | API call (immediate) | `notionAdapter.ts` |
| **GitHub README** | âŒ No | Create PR (manual merge) | `readmeAdapter.ts` |
| **Backstage catalog-info.yaml** | âŒ No | Create PR (manual merge) | `backstageAdapter.ts` |
| **GitBook** | âŒ No | Create PR (manual merge) | `gitbookAdapter.ts` |
| **Swagger/OpenAPI** | âŒ No | Create PR (manual merge) | `swaggerAdapter.ts` |
| **GitHub Checks** | âœ… Yes | GitHub Check API (real-time) | `githubCheck.ts` |

#### Direct Writeback (Confluence, Notion)

When user clicks **Approve** in Slack:
1. Fetch current page version
2. Check version hasn't changed since baseline (optimistic locking)
3. Apply unified diff to page content
4. Update page via API with new version number
5. Add comment: "Updated by VertaAI from [signal source]"

**Example Confluence API call:**
```typescript
PUT /wiki/api/v2/pages/{pageId}
{
  "id": "164013",
  "status": "current",
  "title": "Deployment Runbook",
  "body": {
    "representation": "storage",
    "value": "<updated HTML content>"
  },
  "version": {
    "number": 3,  // Incremented from current version
    "message": "Updated by VertaAI from PR #1234"
  }
}
```

#### PR Workflow (GitHub-based docs)

When user clicks **Approve** in Slack:
1. Create new branch: `vertaai/drift-fix-{driftId}`
2. Apply unified diff to file
3. Commit with message: `[VertaAI] {summary}`
4. Create PR with:
   - Title: `[VertaAI] {summary}`
   - Body: Links to source signal, confidence score, evidence
   - Base branch: `main` (configurable)
5. Post PR URL back to Slack
6. User manually reviews and merges PR

**Why PR workflow for GitHub docs?**
- Code-adjacent documentation should go through code review
- Allows CI checks to run (linting, tests)
- Maintains git history and blame
- Safer for critical docs like API specs

#### GitHub Check Workflow (Agent PR Gatekeeper)

When a PR is opened or updated:
1. **Agent Detection**: Analyze PR author, commit messages, size, and code patterns
2. **Risk Assessment**: Calculate risk tier based on:
   - Agent confidence (30% weight)
   - High-risk domains touched (25% per domain, capped at 50%)
   - Missing evidence requirements (15% per item, capped at 45%)
   - Impact score from deterministic rules (20% weight)
   - Correlated incidents/alerts (10% per incident, capped at 30%)
3. **Delta Sync Analysis**: Analyze IaC, API, and ownership changes using existing parsers
4. **Create GitHub Check** with:
   - **Conclusion**: `success` (PASS), `neutral` (INFO/WARN), `failure` (BLOCK)
   - **Summary**: Risk tier, impact band, correlated signals count
   - **Annotations**: File-level findings from delta sync (max 50)
   - **Details**: Evidence requirements, domain analysis, delta sync findings
5. **Risk Tiers**:
   - **PASS** (<30%): âœ… Green check, no action needed
   - **INFO** (30-60%): â„¹ï¸ Neutral, informational warnings
   - **WARN** (60-80%): âš ï¸ Neutral, requires attention
   - **BLOCK** (â‰¥80%): âŒ Red X, blocks merge (if configured)

**Example GitHub Check:**
```
VertaAI Agent PR Gatekeeper
Status: âš ï¸ WARN (Risk: 72%)

Summary:
- Agent Confidence: 85% (likely agent-authored)
- High-Risk Domains: deployment, database
- Missing Evidence: rollback note, migration note
- Impact Band: ğŸŸ  high
- Correlated Signals: 2 incidents in past 7 days

Delta Sync Findings (3):
- [CRITICAL] IaC drift: Database infrastructure change detected
- [HIGH] API drift: Breaking API change in openapi.yaml
- [MEDIUM] Ownership drift: 2 CODEOWNERS rules changed

Suggested Actions:
- Add rollback procedure to PR description
- Add database migration note
- Review correlated incidents: INC-123, INC-456
```

### Signal Normalization

All signals are normalized to a common `SignalEvent` schema:

```typescript
model SignalEvent {
  workspaceId String
  id          String
  sourceType  String  // 'github_pr', 'pagerduty_incident', 'slack_cluster'
  repo        String?
  service     String?
  extracted   Json    // Source-specific data
  rawPayload  Json    // Original webhook payload
  createdAt   DateTime
  @@id([workspaceId, id])
}
```

This allows the state machine to process all signals uniformly.

---

## User Onboarding & Setup

### Onboarding Flow

```
1. Sign up with Slack
   â†“
2. Connect GitHub (OAuth App)
   â†“
3. Connect Confluence or Notion (OAuth)
   â†“
4. Configure doc mappings (repo â†’ doc)
   â†“
5. (Optional) Connect PagerDuty
   â†“
6. Test with sample PR
   â†“
7. Go live!
```

### Step-by-Step Setup Guide

#### 1. Sign Up with Slack

**URL:** `https://app.vertaai.com/auth/slack`

**What happens:**
- Slack OAuth flow
- Creates workspace in VertaAI
- Installs VertaAI Slack app to your workspace
- Grants permissions:
  - `chat:write` - Send messages
  - `channels:read` - List channels
  - `users:read` - Resolve user mentions
  - `im:write` - Send DMs

**Result:** You're logged into VertaAI dashboard

---

#### 2. Connect GitHub

**Dashboard:** Settings â†’ Integrations â†’ GitHub â†’ "Connect"

**What happens:**
- GitHub OAuth flow
- Installs VertaAI GitHub App to selected repos
- Grants permissions:
  - `contents:read` - Read code and CODEOWNERS
  - `pull_requests:read` - Read PR metadata
  - `webhooks:write` - Register webhook

**Webhook registered:**
```
URL: https://api.vertaai.com/webhooks/github/{workspaceId}
Events: pull_request (merged)
Secret: Auto-generated, stored in Integration table
```

**Result:** GitHub PRs will now trigger drift detection

---

#### 3. Connect Documentation Platform

**Option A: Confluence**

Dashboard â†’ Integrations â†’ Confluence â†’ "Connect"

- Confluence OAuth flow (Atlassian)
- Grants permissions:
  - `read:confluence-content.all`
  - `write:confluence-content`
  - `read:confluence-space.summary`
- Stores OAuth tokens in Integration table

**Option B: Notion**

Dashboard â†’ Integrations â†’ Notion â†’ "Connect"

- Notion OAuth flow
- Grants permissions:
  - `Read content`
  - `Update content`
  - `Read comments`
- Stores OAuth tokens in Integration table

**Result:** VertaAI can fetch and update docs

---

#### 4. Configure Doc Mappings

**Dashboard:** Settings â†’ Doc Mappings â†’ "Add Mapping"

**Mapping structure:**
```typescript
{
  repo: "acme/api-service",        // GitHub repo
  sourceType: "github_pr",         // Signal source
  docId: "164013",                 // Confluence page ID or Notion page ID
  docSystem: "confluence",         // confluence | notion | readme | backstage
  category: "runbook",             // runbook | onboarding | decision | api_spec
  priority: "primary"              // primary | secondary
}
```

**Example mappings:**

| Repo | Source | Doc System | Doc ID | Category | Priority |
|------|--------|------------|--------|----------|----------|
| `acme/api-service` | `github_pr` | `confluence` | `164013` | `runbook` | `primary` |
| `acme/api-service` | `pagerduty_incident` | `confluence` | `164013` | `runbook` | `primary` |
| `acme/frontend` | `github_pr` | `notion` | `abc123` | `onboarding` | `primary` |
| `acme/platform` | `github_pr` | `readme` | `README.md` | `readme` | `primary` |

**How to find doc IDs:**

- **Confluence:** Page ID is in URL: `https://your-domain.atlassian.net/wiki/spaces/SD/pages/164013/Page+Title` â†’ `164013`
- **Notion:** Page ID is in URL: `https://notion.so/Page-Title-abc123def456` â†’ `abc123def456`
- **GitHub README:** Use file path: `README.md` or `docs/deployment.md`

**Result:** VertaAI knows which docs to update for each repo

---

#### 5. (Optional) Connect PagerDuty

**Dashboard:** Settings â†’ Integrations â†’ PagerDuty â†’ "Connect"

**What happens:**
- PagerDuty OAuth flow
- Grants permissions:
  - `Read incidents`
  - `Read services`
  - `Read on-call schedules`
- Registers webhook:
  ```
  URL: https://api.vertaai.com/webhooks/pagerduty/{workspaceId}
  Events: incident.resolved
  ```

**Result:** Resolved incidents will trigger drift detection

---

#### 6. Test with Sample PR

**Dashboard:** Settings â†’ Test â†’ "Trigger Test Drift"

**What happens:**
1. Creates a test `SignalEvent` with sample PR data
2. Creates `DriftCandidate` with state=INGESTED
3. Runs state machine
4. Sends test Slack message to configured channel

**Expected result:**
- Slack message appears in your channel
- Contains sample diff
- Buttons work (Approve, Edit, Reject, Snooze)
- Clicking "Approve" updates the test doc

**If it fails:**
- Check Railway logs for errors
- Verify doc mapping exists
- Verify Slack channel is correct
- Verify OAuth tokens are valid

---

#### 7. Go Live!

**Checklist:**
- âœ… GitHub connected and webhook active
- âœ… Confluence or Notion connected
- âœ… At least one doc mapping configured
- âœ… Test drift completed successfully
- âœ… Slack notifications working

**What to expect:**
- When a PR is merged, you'll see a Slack message within 30-60 seconds
- Message will show proposed diff
- Click "Approve" to update the doc
- Check Confluence/Notion to verify update

---

### Configuration Options

#### Workspace Settings

**Dashboard:** Settings â†’ Workspace

| Setting | Default | Description |
|---------|---------|-------------|
| **Default Slack Channel** | `#engineering` | Where to send drift notifications |
| **Confidence Threshold** | `0.7` | Minimum confidence to send notification (0-1) |
| **Max Diff Lines** | `120` | Maximum diff size before requiring manual review |
| **Auto-Approve Low-Risk** | `false` | Auto-approve diffs with confidence > 0.95 (not recommended) |
| **Rate Limit** | `10/hour` | Max notifications per hour |

#### Eligibility Rules

**Dashboard:** Settings â†’ Eligibility Rules

Control which PRs trigger drift detection:

```yaml
github_pr:
  min_changes: 10              # Ignore tiny PRs
  max_changes: 5000            # Ignore massive refactors
  required_paths:              # At least one file must match
    - "**/deploy/**"
    - "**/infra/**"
    - "**/terraform/**"
    - "**/helm/**"
    - "**/k8s/**"
    - "**/.github/workflows/**"
    - "**/config/**"
  excluded_labels:             # Skip PRs with these labels
    - "skip-vertaai"
    - "docs-only"
  excluded_authors:            # Skip PRs from bots
    - "dependabot[bot]"
    - "renovate[bot]"
```

---

## Integration Compatibility Matrix

### Input Source Ã— Output Target Compatibility

| Input Source | Confluence | Notion | README | Backstage | GitBook | Swagger |
|--------------|------------|--------|--------|-----------|---------|---------|
| **GitHub PR** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| **PagerDuty Incident** | âœ… | âœ… | âŒ | âŒ | âŒ | âŒ |
| **Slack Questions** | âœ… | âœ… | âŒ | âŒ | âŒ | âŒ |

**Why some combinations don't work:**
- **PagerDuty â†’ GitHub docs:** Incidents rarely relate to code-adjacent docs (README, Backstage, etc.)
- **Slack â†’ GitHub docs:** Knowledge gaps are better documented in wikis, not code repos

### Drift Type Ã— Doc Category Routing

| Drift Type | Runbook | Onboarding | Decision Doc | API Spec | Ownership |
|------------|---------|------------|--------------|----------|-----------|
| **Instruction** | âœ… Primary | âœ… | âŒ | âœ… | âŒ |
| **Process** | âœ… | âœ… Primary | âœ… Primary | âŒ | âŒ |
| **Ownership** | âœ… | âœ… | âŒ | âŒ | âœ… Primary |
| **Coverage** | âœ… Primary | âœ… | âœ… | âœ… | âŒ |
| **Environment/Tooling** | âœ… Primary | âœ… | âœ… | âŒ | âŒ |

**Example:**
- PR changes `kubectl` â†’ `helm` (Instruction drift) â†’ Updates **Runbook**
- Incident reveals new failure mode (Coverage drift) â†’ Updates **Runbook**
- PR changes team ownership (Ownership drift) â†’ Updates **Ownership doc** (CODEOWNERS, team page)

### Update Method by Doc System

| Doc System | Update Method | Approval Required? | Version Control? |
|------------|---------------|-------------------|------------------|
| **Confluence** | Direct API write | âœ… Yes (Slack) | âœ… Page versions |
| **Notion** | Direct API write | âœ… Yes (Slack) | âœ… Page history |
| **README** | GitHub PR | âœ… Yes (Slack + PR review) | âœ… Git history |
| **Backstage** | GitHub PR | âœ… Yes (Slack + PR review) | âœ… Git history |
| **GitBook** | GitHub PR | âœ… Yes (Slack + PR review) | âœ… Git history |
| **Swagger** | GitHub PR | âœ… Yes (Slack + PR review) | âœ… Git history |

---

## Key Technical Concepts

### 1. Contract Packs & Invariants

**Contract Packs** are collections of invariants that define what should be consistent across your operational stack.

**Key Concepts:**

- **ContractPack**: A named collection of invariants with scope rules (which repos/services/files it applies to)
- **Invariant**: A single consistency rule (e.g., "all OpenAPI endpoints must be documented in Confluence")
- **Artifact Roles**: Each invariant defines which artifacts to compare:
  - `primary`: Source of truth (e.g., OpenAPI spec)
  - `secondary`: Derived artifact (e.g., Confluence docs)
  - `reference`: Additional context (e.g., Grafana dashboard)
- **Comparator Type**: Which comparator to use (e.g., `openapi_docs_endpoint_parity`)
- **Expected Outcome**: What success looks like (e.g., `all_endpoints_documented`)

**Example Contract Pack:**

```typescript
{
  name: "API Documentation Consistency",
  description: "Ensures OpenAPI spec matches Confluence API docs",
  scope: {
    repos: ["acme/api-service"],
    services: ["api-service"],
    filePatterns: ["**/openapi.yaml", "**/swagger.json"]
  },
  invariants: [
    {
      invariantId: "endpoint-parity",
      comparatorType: "openapi_docs_endpoint_parity",
      artifactRoles: {
        primary: { type: "openapi", locator: "openapi.yaml" },
        secondary: { type: "confluence_page", locator: "164013" }
      },
      expectedOutcome: "all_endpoints_documented"
    },
    {
      invariantId: "schema-parity",
      comparatorType: "openapi_docs_schema_parity",
      artifactRoles: {
        primary: { type: "openapi", locator: "openapi.yaml" },
        secondary: { type: "confluence_page", locator: "164013" }
      },
      expectedOutcome: "all_schemas_documented"
    }
  ]
}
```

### 2. Contract Resolution Strategies

When a PR is opened, VertaAI resolves which contracts apply using 5 strategies (in priority order):

| Strategy | Confidence | How It Works | Example |
|----------|-----------|--------------|---------|
| **explicit_path** | 1.0 | Exact file path match | `scope.filePaths = ["openapi.yaml"]` |
| **file_pattern** | 0.7-1.0 | Glob pattern match | `scope.filePatterns = ["**/openapi.yaml"]` |
| **directory_pattern** | 0.7 | Directory match | `scope.directoryPatterns = ["deploy/**"]` |
| **codeowners** | 0.75 | CODEOWNERS team match | `scope.codeownersTeams = ["@platform-team"]` |
| **service_tag** | 0.6 | Service name match | `scope.services = ["api-service"]` |

**Why confidence matters:** Higher confidence = more likely to block merge on failure.

### 3. Artifact Snapshots & Versioning

Every artifact is fetched and stored as an immutable snapshot:

```typescript
model ArtifactSnapshot {
  workspaceId     String
  id              String
  artifactType    String      // 'openapi', 'confluence_page', 'terraform_config'
  artifactLocator String      // URL, file path, or ID
  content         Json        // Parsed artifact content
  rawContent      String?     // Original raw content
  version         String?     // Artifact version (if available)
  fetchedAt       DateTime
  expiresAt       DateTime    // TTL for cleanup
  @@id([workspaceId, id])
}
```

**Benefits:**
- âœ… **Reproducibility**: Can replay comparisons with exact same data
- âœ… **Performance**: No need to re-fetch artifacts for multiple comparisons
- âœ… **Auditability**: Full history of what was compared
- âœ… **TTL Cleanup**: Automatic cleanup after 24 hours (configurable)

### 4. Comparators & IntegrityFindings

**Comparators** are deterministic, stateless functions that compare artifact snapshots and produce structured findings.

**Key Properties:**
- âœ… **Deterministic**: Same input always produces same output (no LLM calls)
- âœ… **Fast**: Complete in < 5 seconds
- âœ… **Stateless**: No side effects, easy to test
- âœ… **Pluggable**: Easy to add new comparators

**Comparator Types (Implemented):**
1. **OpenAPI â†” Docs** (`openapi_docs_endpoint_parity`):
   - Detects missing endpoints (in OpenAPI but not in docs)
   - Detects deprecated endpoints (in docs but not in OpenAPI)
   - Detects missing parameters (required/optional)
   - Detects missing schemas
   - Detects missing examples

**Comparator Types (Planned):**
2. **Terraform â†” Runbook** (`terraform_runbook_consistency`):
   - Detects infrastructure drift (regions, resources, configs)
   - Detects missing deployment steps
   - Detects outdated rollback procedures

3. **Dashboard â†” Alert** (`dashboard_alert_metric_parity`):
   - Detects metric name mismatches
   - Detects missing alerts for dashboard panels
   - Detects threshold inconsistencies

4. **CODEOWNERS â†” Docs** (`codeowners_docs_ownership_parity`):
   - Detects ownership drift (team renames, moves)
   - Detects missing ownership documentation

**IntegrityFinding Structure:**

```typescript
model IntegrityFinding {
  workspaceId       String
  id                String
  contractId        String
  invariantId       String
  signalEventId     String
  driftType         String      // 'endpoint_missing', 'schema_mismatch', etc.
  severity          String      // 'critical', 'high', 'medium', 'low'
  evidence          Json        // Structured evidence with pointers
  comparedArtifacts Json        // Which snapshots were compared
  recommendedAction String      // 'block_merge', 'create_patch_candidate', 'notify', 'no_action'
  confidence        Float       // 0.0-1.0
  impact            Float       // 0.0-1.0
  band              String      // 'pass', 'warn', 'fail'
  routedTo          Json        // Who should be notified
  createdAt         DateTime
  @@id([workspaceId, id])
}
```

**Evidence Structure:**

```typescript
{
  kind: "endpoint_missing",
  leftValue: { method: "POST", path: "/api/users", summary: "Create user" },
  rightValue: null,
  leftSnippet: "POST /api/users - Create a new user account",
  rightSnippet: null,
  pointers: {
    left: "paths./api/users.post",
    right: null
  }
}
```

### 5. Drift Types & Orthogonal Coverage

VertaAI classifies drift into 4 primary types, with **coverage as an orthogonal dimension**:

| Type | Description | Example | Detection Method |
|------|-------------|---------|------------------|
| **Instruction** | Commands, configs, URLs are wrong | `kubectl` â†’ `helm` | Deterministic artifact comparison |
| **Process** | Workflow/sequence changed | "Deploy to staging first" â†’ "Deploy to prod directly" | Deterministic artifact comparison |
| **Ownership** | Team structure, contacts, on-call changed | Team moved from `#backend` to `#platform` | CODEOWNERS diff + PagerDuty API |
| **Environment/Tooling** | Infrastructure, deployment tools changed | Jenkins â†’ GitHub Actions | Deterministic artifact comparison |

**Orthogonal Coverage Dimension**:

Coverage gaps are detected **independently** and can apply to ANY drift type:

- **Instruction + Coverage**: Doc has wrong command AND doesn't cover the new scenario
- **Process + Coverage**: Doc has outdated steps AND doesn't cover the new workflow
- **Ownership + Coverage**: Doc has wrong owner AND doesn't cover the new team structure
- **Environment + Coverage**: Doc has wrong tool AND doesn't cover the new platform

**How Coverage Detection Works**:
1. Extract artifacts from source signal (new commands, steps, scenarios)
2. Extract artifacts from documentation (current coverage)
3. Compare: Does doc mention the new scenario?
4. If not â†’ Set `hasCoverageGap = true` (orthogonal to drift type)

**Example**:
- **Source**: PR adds new rollback procedure using Helm
- **Doc**: Deployment runbook only covers forward deployment with kubectl
- **Detection**: `driftType = "instruction"` + `hasCoverageGap = true`
- **Slack**: "ğŸ“‹ Instruction Drift + ğŸ“Š Coverage Gap Detected"

### 6. Evidence-Based Detection (EvidenceBundle Pattern + Typed Deltas)

**Purpose:** Deterministic, reproducible drift detection without LLM randomness. Produces machine-readable typed deltas that flow directly to LLM agents.

**How it works:**
1. **Extract artifacts from source signal** (with bounded context expansion):
   - Commands: `kubectl apply`, `helm install`, `docker run`
   - URLs: API endpoints, service URLs, documentation links
   - Config values: Environment variables, settings, parameters (key:value pairs)
   - Process steps: Deployment steps, runbook procedures, workflows
   - Ownership: Teams, channels, on-call rotations, CODEOWNERS
   - Environment: Tools, platforms, versions, dependencies
   - When available, full file content (up to 3 key files, 30K chars) enriches artifact extraction beyond diff-only context

2. **Extract artifacts from documentation**:
   - Parse current doc content for same artifact types
   - Build structured representation of doc state

3. **Deterministic comparison with typed deltas**:
   - Compare source artifacts vs doc artifacts using typed delta comparison
   - **Key:value comparison** for config keys (detects value changes, not just presence)
   - **Tool replacement detection**: A removed + B added in same artifact category
   - **Version mismatch detection**: Pinned version changes (e.g., `node:18` â†’ `node:20`)
   - Detect coverage gaps (source has X, doc doesn't mention it)
   - Each difference produces a `TypedDelta`: `{artifactType, action, sourceValue, docValue, section, confidence}`
   - Calculate overall confidence score (0.0 to 1.0) based on artifact overlap

4. **Classification**:
   - If confidence â‰¥ 0.6 â†’ Use comparison result (deterministic)
   - If confidence < 0.6 â†’ Use default type (deterministic_low_confidence)
   - No drift â†’ Mark as COMPLETED

**EvidenceBundle Model:**
```typescript
{
  workspaceId: string;
  id: string;
  driftId: string;
  sourceArtifacts: Json; // Extracted from signal (+ file context when available)
  docArtifacts: Json;    // Extracted from documentation
  comparisonResult: {
    driftType: string;
    hasCoverageGap: boolean;
    confidence: number;
    conflicts: Array<{type, source, doc}>;
    gaps: Array<{type, content}>;
    typedDeltas: Array<{        // Machine-readable deltas for LLM agents
      artifactType: string;     // 'command' | 'configKey' | 'endpoint' | 'tool' | 'version' | ...
      action: string;           // 'added' | 'removed' | 'changed' | 'missing_in_doc'
      sourceValue: string;
      docValue?: string;
      section?: string;
      confidence: number;
    }>;
  };
  assessment: {
    impactBand: string;         // 'critical' | 'high' | 'medium' | 'low'
    consequenceText: string;    // Deterministic impact narrative
    firedRules: string[];       // Which comparison rules matched
  };
  createdAt: DateTime;
}
```

**Why this matters:**
- **100% Reproducible**: Same input always produces same output
- **Fast**: No LLM calls needed for classification (~10x faster)
- **Transparent**: Typed deltas explain exactly what changed, how, and where
- **Evidence-grounded**: LLM agents receive structured deltas, not raw text â€” preventing hallucination
- **Accurate**: Detects 5 types of drift across 7 source types with key:value depth
- **Auditable**: Full evidence trail with per-delta provenance for compliance

### 7. Patch Generation (Unified Diff)

**Key constraint:** Generate diffs, not full rewrites

**Unified diff format:**
```diff
--- a/deployment-runbook.md
+++ b/deployment-runbook.md
@@ -15,7 +15,7 @@
 ## Deploy to Production

 1. Merge PR to `main`
-2. Run: `kubectl apply -f k8s/deployment.yaml`
+2. Run: `helm install api-service ./chart`
 3. Verify pods are running: `kubectl get pods`
 4. Check logs: `kubectl logs -f deployment/api-service`
```

**Why diffs?**
- âœ… Reviewable (like a PR)
- âœ… Version controlled (can revert)
- âœ… Scoped (only changes what's needed)
- âœ… Explainable (shows before/after)
- âœ… Testable (can validate diff applies cleanly)

**Diff constraints:**
- Max 120 lines
- Only modify within allowed sections (marked with `<!-- DRIFT_AGENT_MANAGED -->`)
- No secrets (validated with regex)
- Must apply cleanly to current doc version

### 8. Owner Resolution

**Priority chain:**

```
1. CODEOWNERS file (if repo has one)
   â”œâ”€ Parse file
   â”œâ”€ Match changed file paths
   â””â”€ Extract @team or @user

2. Doc ownership mapping (manual config)
   â””â”€ DocMappingsV2.owner field

3. PagerDuty on-call (if PagerDuty connected)
   â”œâ”€ Match service name
   â””â”€ Get current on-call user

4. Workspace default owner (fallback)
   â””â”€ Workspace.defaultSlackChannel
```

**Example:**

```
PR changes: deploy/k8s/deployment.yaml

CODEOWNERS:
  deploy/** @platform-team

Result: Send Slack message to #platform-team
```

### 9. Notification Routing

**Decision tree:**

```
Confidence >= 0.9 â†’ Send to owner's channel
Confidence 0.7-0.9 â†’ Send to owner's channel (with warning)
Confidence 0.5-0.7 â†’ Send to review queue
Confidence < 0.5 â†’ Don't send (log only)
```

**Rate limiting:**
- Max 10 notifications per hour per workspace (configurable)
- Deduplication: Same drift fingerprint within 24 hours â†’ Skip

### 10. Managed Regions

**Purpose:** Limit where VertaAI can make changes

**Syntax:**
```markdown
<!-- DRIFT_AGENT_MANAGED: deployment -->
## Deployment Steps

1. Run: `kubectl apply -f deployment.yaml`
2. Verify: `kubectl get pods`
<!-- END_DRIFT_AGENT_MANAGED -->

## Manual Steps (DO NOT AUTO-UPDATE)

These steps require human judgment...
```

**Behavior:**
- VertaAI can only modify content within `DRIFT_AGENT_MANAGED` blocks
- Attempts to modify outside blocks â†’ Validation fails
- If no managed blocks â†’ Entire doc is fair game (risky!)

**Best practice:** Mark operational sections as managed, leave strategic/judgment sections unmanaged

### 11. Audit Trail & Compliance

**Purpose:** Complete observability and compliance for all drift processing decisions

**Components:**

#### PlanRun Tracking
Every drift is linked to a PlanRun record that captures:
- Which plan version was active (`activePlanId`, `activePlanVersion`, `activePlanHash`)
- What thresholds were used (snapshot at execution time)
- What routing decision was made (`auto_approve`, `slack_notify`, `digest_only`, `ignore`)
- Timestamp of execution

**Why this matters:**
- **Reproducibility**: Can replay exact routing decision from any point in time
- **Auditability**: Full history of which plan was used for each drift
- **Debugging**: Understand why a drift was routed a certain way

#### AuditEvent Model
All significant actions are logged as audit events:
- Drift state transitions
- Human actions (approve, reject, snooze, edit)
- Budget enforcement decisions
- Noise filtering decisions
- Writeback operations
- Errors and failures

**AuditEvent Schema:**
```typescript
{
  workspaceId: string;
  id: string;
  entityType: 'drift' | 'plan' | 'workspace';
  entityId: string;
  eventType: string; // 'approved', 'rejected', 'snoozed', 'budget_exceeded', etc.
  payload: Json;     // Event-specific data
  actorType: 'human' | 'system' | 'llm';
  actorId: string;   // User ID or 'drift-agent'
  createdAt: DateTime;
}
```

**Benefits:**
- âœ… **Compliance**: Full audit trail for SOC2, ISO27001, GDPR
- âœ… **Debugging**: Trace every decision and action
- âœ… **Analytics**: Understand system behavior and user patterns
- âœ… **Accountability**: Know who did what and when

### 12. Early Threshold Routing + Materiality Gate

**Purpose:** Two-layer pre-patch filter at BASELINE_CHECKED that prevents both low-confidence AND low-value drifts from reaching the LLM.

**Layer 1 â€” Confidence Threshold Routing:**
1. At BASELINE_CHECKED state (before PATCH_PLANNED)
2. Resolve active DriftPlan and thresholds
3. Check drift confidence against ignore threshold
4. If confidence < ignore threshold â†’ Skip to COMPLETED

**Layer 2 â€” Materiality Gate (runs after threshold check passes):**
1. Examine typed deltas from the EvidenceBundle
2. Apply deterministic materiality rules:
   - **Skip** if `impactBand = low` AND only 1 typed delta AND `delta.confidence < 0.5`
   - **Skip** if managed region missing in target doc AND change is non-additive (removal/change, not addition)
   - **Skip** if all deltas are tag-only changes with no semantic content change
3. If not material â†’ Skip to COMPLETED with `materialitySkipReason` persisted
4. Skip reasons feed into temporal drift accumulation (Phase 5)

**Implementation:**
```typescript
// At BASELINE_CHECKED state
const confidence = drift.confidence || 0.5;
const threshold = resolveThresholds({...});

// Layer 1: Confidence threshold
if (confidence < threshold.ignore) {
  return { state: DriftState.COMPLETED, enqueueNext: false };
}

// Layer 2: Materiality gate
const materialityResult = evaluateMateriality(evidenceBundle.typedDeltas, evidenceBundle.assessment);
if (!materialityResult.isMaterial) {
  await persistMaterialitySkip(drift.id, materialityResult.skipReason);
  await recordTemporalDriftEvent(drift.docId, materialityResult); // Feed to Phase 5
  return { state: DriftState.COMPLETED, enqueueNext: false };
}
```

**Benefits:**
- âœ… **Cost Savings**: 30-40% reduction from threshold routing + additional ~30% from materiality gate
- âœ… **Noise Elimination**: Low-value patches (tag-only, single low-confidence delta) never reach LLM
- âœ… **Faster Processing**: Non-material drifts complete immediately
- âœ… **Temporal Tracking**: Skip reasons feed into drift accumulation for future bundled updates

**Example:**
- Drift confidence: 0.15, Ignore threshold: 0.20 â†’ **Skipped by threshold** (saves 2-3 LLM calls)
- Drift confidence: 0.65, but single delta with `impactBand=low` and `confidence=0.4` â†’ **Skipped by materiality gate** (skip reason persisted for temporal bundling)

### 9. Cluster-First Drift Triage

**Purpose:** Reduce notification fatigue by grouping similar drifts

**How it works:**
1. At OWNER_RESOLVED state (after patch generation)
2. Check if clustering is enabled (`DriftPlan.budgets.enableClustering`)
3. Extract cluster key: `{service}_{driftType}_{fingerprintPattern}`
4. Find or create cluster within 1-hour time window
5. Add drift to cluster
6. Check notification criteria:
   - 2+ drifts in cluster â†’ Send cluster notification
   - 1 hour expiry â†’ Send cluster notification
   - Max cluster size (20) reached â†’ Send cluster notification
7. Send aggregated Slack message with bulk actions

**Cluster Slack Message:**
```
ğŸ”„ 5 Similar Drifts Detected

Service: api-service
Type: Instruction Drift
Pattern: kubectl â†’ helm
Avg Confidence: 87%
Sources: 3 PRs, 2 incidents

Drifts:
1. PR #1234 - Migrate deployment (92%) [Review]
2. PR #1235 - Remove kubectl files (85%) [Review]
3. Incident P-123 - Deployment failure (83%) [Review]
... (2 more)

[âœ… Approve All] [ğŸ‘€ Review Individually] [âŒ Reject All] [ğŸ’¤ Snooze All]
```

**Benefits:**
- âœ… **80-90% Notification Reduction**: 50 drifts â†’ 5-10 clusters
- âœ… **Bulk Actions**: 1 click approves 5-10 drifts
- âœ… **Better UX**: Less notification fatigue, higher engagement
- âœ… **OPT-IN**: Enable per DriftPlan for gradual rollout

**Status:** âœ… Fully implemented and verified functional (P0-2 audit)

### 10. Agent PR Gatekeeper

**Purpose:** Detect agent-authored PRs (Claude, ChatGPT, Copilot, etc.) and gate risky changes with evidence-based checks to reduce review overload and prevent unsafe merges.

**Target Users:** Platform/Eng Productivity/Staff Engineers who own merge hygiene

**How it works:**

#### 1. Agent Detection (Deterministic Heuristics)

Detects agent-authored PRs using multiple signals:

- **Author patterns**: Matches `copilot`, `claude`, `gpt`, `chatgpt`, `ai-`, `bot`, `assistant`, `codewhisperer`, `tabnine`, `cursor`, `aider`, `augment`
- **Commit message markers**: Detects `Co-authored-by: GitHub Copilot`, `Generated by Claude`, `AI-generated`, etc.
- **PR size threshold**: Flags PRs with >1000 lines changed
- **Tool signatures**: Detects `// Generated by`, `@generated`, `# Auto-generated` in code
- **Confidence scoring**: Additive weights, capped at 1.0, threshold at 0.50

#### 2. Risk Tier Calculation (Multi-Factor Scoring)

Calculates risk score (0-100%) based on:

| Factor | Weight | Description |
|--------|--------|-------------|
| **Agent Confidence** | 30% | How confident we are this is agent-authored |
| **High-Risk Domains** | 25% per domain (max 50%) | IaC, auth, deployment, database, API contracts |
| **Missing Evidence** | 15% per item (max 45%) | Tests, rollback notes, migration notes, runbook links |
| **Impact Score** | 20% | Deterministic impact assessment from rules matrix |
| **Correlated Incidents** | 10% per incident (max 30%) | Recent incidents/alerts for same service (7-day window) |

**Risk Tiers:**
- **PASS** (<30%): âœ… Green check, safe to merge
- **INFO** (30-60%): â„¹ï¸ Informational, review recommended
- **WARN** (60-80%): âš ï¸ Warning, requires attention
- **BLOCK** (â‰¥80%): âŒ Blocks merge, high risk

#### 3. Evidence Requirements (Domain-Specific Checklist)

Deterministic checklist based on domains touched:

| Domain | Required Evidence |
|--------|-------------------|
| **Deployment/IaC** | Rollback procedure, deployment runbook link |
| **Database/Schema** | Migration note, rollback plan |
| **Auth/Security** | Security review note, threat model update |
| **API Contract** | Breaking change note, migration guide |
| **All PRs** | Tests changed OR explicit "no tests needed" note |

#### 4. Delta Sync Findings (Reuses Existing Parsers)

Analyzes PR changes using existing drift detection parsers:

**IaC Analysis** (`iacParser.ts`):
- Detects Terraform/Pulumi/CloudFormation changes
- Classifies: deployment infrastructure, database infrastructure, security infrastructure
- Severity: high (deployment), critical (database/security)
- Suggests: deployment runbook, migration guide, security policies

**API Analysis** (`openApiParser.ts`):
- Detects OpenAPI/Swagger spec changes
- Classifies: breaking vs non-breaking changes
- Severity: critical (breaking), medium (non-breaking)
- Suggests: API documentation, migration guide, changelog

**Ownership Analysis** (`codeownersParser.ts`):
- Detects CODEOWNERS file changes
- Classifies: ownership rule changes
- Severity: medium/high (based on count)
- Suggests: team structure docs, on-call rotation docs

#### 5. Impact Assessment Integration

Reuses existing `impactAssessment.ts` service:

1. Builds `SourceEvidence` from PR data (files changed, lines added/removed, PR title/body)
2. Builds `TargetEvidence` (defaults to runbook surface for high-risk domains)
3. Calls `computeImpactAssessment()` using deterministic rules matrix
4. Returns: `impactScore` (0-1), `impactBand` (low/medium/high/critical)

#### 6. Signal Correlation Integration

Reuses existing `signalJoiner.ts` service:

1. Creates signal ID: `github_pr_{owner}_{repo}_{prNumber}`
2. Infers service name from file paths (e.g., `services/api/...` â†’ `api`)
3. Calls `joinSignals()` to find correlated incidents/alerts within 7-day window
4. Boosts risk score when correlated signals are found

#### 7. GitHub Check Output

Creates GitHub Check run with:

**Summary:**
- Risk tier with emoji (âœ… PASS, â„¹ï¸ INFO, âš ï¸ WARN, âŒ BLOCK)
- Risk score percentage
- Agent confidence
- Impact band (ğŸŸ¢ low, ğŸŸ¡ medium, ğŸŸ  high, ğŸ”´ critical)
- Correlated signals count
- Delta sync findings count

**Annotations** (max 50):
- File-level findings from delta sync analysis
- Severity mapping: criticalâ†’failure, highâ†’warning, medium/lowâ†’notice
- Includes suggested docs to update

**Details:**
- Evidence requirements checklist
- High-risk domains detected
- Delta sync findings with descriptions
- Suggested actions

**Example:**
```
VertaAI Agent PR Gatekeeper
Status: âš ï¸ WARN (Risk: 72%)

Agent Confidence: 85%
Impact Band: ğŸŸ  high
Correlated Signals: 2 incidents
Delta Sync Findings: 3 (1 critical, 2 high)

Missing Evidence:
- âŒ Rollback procedure
- âŒ Database migration note

High-Risk Domains:
- deployment
- database

Delta Sync Findings:
1. [CRITICAL] IaC drift: Database infrastructure change in terraform/rds.tf
   Suggested docs: migration guide, rollback plan
2. [HIGH] API drift: Breaking change in openapi.yaml (removed endpoint)
   Suggested docs: API documentation, migration guide
3. [HIGH] Ownership drift: 2 CODEOWNERS rules changed
   Suggested docs: team structure docs
```

**Benefits:**
- âœ… **Reduces Review Overload**: Automated risk assessment for agent PRs
- âœ… **Prevents Unsafe Merges**: Blocks high-risk changes without evidence
- âœ… **Evidence-Based**: Deterministic checks, no LLM randomness
- âœ… **Reuses Existing Infrastructure**: 85% code reuse from drift detection
- âœ… **Real-Time Feedback**: GitHub Check appears within seconds of PR creation
- âœ… **Actionable**: Clear checklist of what's needed to pass

**Status:** âœ… Fully implemented (Phase 1-4 complete)

### 11. Typed Deltas & Evidence-Grounded Patching

**Purpose:** Replace raw diff text with structured, machine-readable typed deltas that flow from deterministic comparison all the way to LLM agents.

**What are Typed Deltas?**

A `TypedDelta` is a machine-readable object that describes a single, atomic difference between a source signal and a target document:

```typescript
interface TypedDelta {
  artifactType: 'command' | 'configKey' | 'endpoint' | 'tool' | 'step' | 'owner' | 'version' | 'dependency' | 'scenario';
  action: 'added' | 'removed' | 'changed' | 'missing_in_doc';
  sourceValue: string;       // What the source signal says
  docValue?: string;         // What the doc currently says (if applicable)
  section?: string;          // Which doc section is affected
  confidence: number;        // Per-delta confidence (0.0-1.0)
}
```

**How Typed Deltas flow to LLM agents:**

Instead of passing raw `diffExcerpt` + `prTitle` + `prDescription` to the patch planner and generator, the system now passes a **structured evidence contract**:

```typescript
interface EvidenceContract {
  typedDeltas: TypedDelta[];        // Machine-readable deltas
  consequenceText: string;          // Deterministic impact narrative
  impactBand: 'critical' | 'high' | 'medium' | 'low';
  sourceType: string;               // github_pr, pagerduty_incident, etc.
  driftType: string;                // instruction, process, ownership, etc.
  firedRules: string[];             // Which comparison rules matched
}
```

**Truncation priority order:** When the LLM token budget is tight, deltas are prioritized:
1. `critical` and `high` impact deltas always included
2. `medium` deltas included if budget allows
3. `low` impact deltas dropped first

**Comparison depth improvements:**
- **Config keys**: Compared by key name AND value (detects `DB_HOST=localhost` â†’ `DB_HOST=prod.db.com`)
- **Tool replacement**: Detects when tool A is removed AND tool B is added (e.g., `kubectl` â†’ `helm`)
- **Version mismatch**: Detects pinned version changes (e.g., `node:18` â†’ `node:20`)

### 11. Bounded Context Expansion

**Purpose:** Fetch full file content for key changed files to provide richer artifact extraction beyond diff-only context.

**The problem:**
Without context expansion, artifact extraction operates only on diff text â€” the lines that changed. This means a config key that appears in the diff but whose full context (surrounding keys, file structure) is in the unchanged portion of the file goes undetected.

**How it works:**
1. At DOCS_FETCHED state, after fetching the target doc
2. Identify key changed files from the source signal (PR file list)
3. Apply file selection heuristic (prioritize operational files):
   - `*.yaml`, `*.yml`, `*.conf`, `*.toml`, `*.ini` (config files)
   - `Dockerfile`, `docker-compose.yml` (container definitions)
   - `*.tf`, `*.tfvars` (Terraform infrastructure)
   - `*.proto`, `openapi.*`, `swagger.*` (API definitions)
   - `CODEOWNERS` (ownership)
4. Fetch up to **3 files**, max **10K chars per file** (30K total budget)
5. Feed full file content into artifact extraction alongside diff text

**Benefits:**
- âœ… **Richer extraction**: Full file context reveals config keys, versions, and tools not visible in diff alone
- âœ… **Bounded by design**: Hard limits on file count (3) and size (30K chars) prevent unbounded expansion
- âœ… **Operational focus**: File selection heuristic targets the files most likely to contain operational truth

### 12. Temporal Drift Accumulation

**Purpose:** Track cumulative drift per document over time, bundling multiple small drifts into comprehensive updates.

**The problem:**
Without temporal tracking, each signal is processed independently. A document that accumulates 10 individually non-material drifts over a week (each skipped by the materiality gate) never gets updated â€” even though the cumulative effect is significant.

**How it works:**
1. Every time the materiality gate **skips** a drift, the skip reason is recorded in a `DriftHistory` record for that document
2. At SIGNALS_CORRELATED, check the drift history for the target document:
   - Count skipped drifts within the configured time window (default: 7 days)
   - If count â‰¥ bundling threshold (default: 5 skips) â†’ **Promote to bundled update**
3. A bundled update aggregates all the skipped typed deltas into a single comprehensive patch
4. The bundled update bypasses the materiality gate (it's already been determined to be material in aggregate)

**DriftHistory Model:**
```typescript
{
  id: string;
  workspaceId: string;
  docId: string;                // Which document this tracks
  driftCandidateId: string;     // The drift that was skipped
  skipReason: string;           // Why materiality gate skipped it
  typedDeltas: TypedDelta[];    // What deltas were skipped
  timeWindow: string;           // '7d', '14d', '30d'
  createdAt: DateTime;
}
```

**Configurable thresholds:**
- `temporalWindow`: Time window for accumulation (default: 7 days)
- `bundlingThreshold`: Number of skips before bundling (default: 5)
- `maxBundleSize`: Maximum deltas in a single bundled update (default: 30)

**Benefits:**
- âœ… **No stale docs**: Documents can't silently accumulate drift indefinitely
- âœ… **Comprehensive updates**: Bundled patches are more valuable than N individual small patches
- âœ… **Configurable**: Teams control the window and threshold per workspace

---

## Example Workflows

### Example 1: Contract Validation - OpenAPI â†” Docs Consistency (Track 1)

**Scenario:** Developer opens PR that adds new endpoint to OpenAPI spec but forgets to update Confluence API docs

**Timeline:**

```
2:00 PM - PR #5678 opened
  â”œâ”€ Changed files: openapi.yaml (added POST /api/users endpoint)
  â”œâ”€ No changes to Confluence docs
  â””â”€ GitHub webhook fires (pull_request.opened)

2:00:02 PM - VertaAI receives webhook
  â”œâ”€ Creates SignalEvent (github_pr)
  â”œâ”€ Dual routing: Contract validation + Drift detection
  â””â”€ Contract validation runs immediately (no queue)

2:00:05 PM - Contract Resolution
  â”œâ”€ Matches file pattern: **/openapi.yaml
  â”œâ”€ Resolves contract: "API Documentation Consistency"
  â”œâ”€ Confidence: 1.0 (explicit_path match)
  â””â”€ Invariants: [endpoint-parity, schema-parity, example-parity]

2:00:08 PM - Artifact Fetching (parallel)
  â”œâ”€ Primary: openapi.yaml from PR branch (GitHub API)
  â”œâ”€ Secondary: Confluence page 164013 (Confluence API)
  â””â”€ Both snapshots stored with 24h TTL

2:00:12 PM - Comparator Execution
  â”œâ”€ OpenApiComparator.compare()
  â”œâ”€ Extracts endpoints from OpenAPI: [GET /api/users, POST /api/users, ...]
  â”œâ”€ Extracts endpoints from Confluence: [GET /api/users, DELETE /api/users, ...]
  â”œâ”€ Detects missing endpoint: POST /api/users (in OpenAPI, not in docs)
  â””â”€ Creates IntegrityFinding:
      {
        driftType: "endpoint_missing",
        severity: "high",
        evidence: {
          kind: "endpoint_missing",
          leftValue: { method: "POST", path: "/api/users", summary: "Create user" },
          rightValue: null,
          pointers: { left: "paths./api/users.post", right: null }
        },
        recommendedAction: "create_patch_candidate",
        confidence: 0.95,
        impact: 0.8,
        band: "fail"
      }

2:00:15 PM - GitHub Check Created
  â”œâ”€ Conclusion: failure (band=fail)
  â”œâ”€ Summary: "âš ï¸ WARN (Risk: 75%) - 1 high-severity finding"
  â”œâ”€ Annotation on openapi.yaml:
      Line 45: "Endpoint POST /api/users is not documented in Confluence"
  â””â”€ Details: Link to Confluence page, suggested action

2:00:16 PM - PR Status Updated
  â”œâ”€ GitHub shows red X on PR
  â”œâ”€ Developer sees inline annotation
  â””â”€ Can click through to see full evidence

2:05 PM - Developer updates Confluence docs
  â”œâ”€ Adds POST /api/users endpoint documentation
  â””â”€ Pushes new commit to PR

2:05:30 PM - VertaAI re-validates
  â”œâ”€ Fetches new snapshots
  â”œâ”€ Comparator runs again
  â”œâ”€ No findings (all endpoints documented)
  â””â”€ GitHub Check: âœ… success (PASS)

2:06 PM - PR approved and merged
```

**Key Benefits:**
- âœ… **Fast feedback**: < 20 seconds from PR open to check result
- âœ… **Inline annotations**: Developer sees exactly what's wrong
- âœ… **Prevents drift**: Catches inconsistency before merge
- âœ… **No LLM calls**: Deterministic, reproducible, fast

---

### Example 2: Drift Remediation - GitHub PR â†’ Confluence Runbook Update (Track 2)

**Scenario:** Developer merges PR that changes deployment from kubectl to Helm

**Timeline:**

```
10:00 AM - PR #1234 merged to main
  â”œâ”€ Changed files: deploy/helm/values.yaml, deploy/k8s/deployment.yaml (deleted)
  â”œâ”€ Diff: "kubectl apply" â†’ "helm install"
  â””â”€ GitHub webhook fires

10:00:05 AM - VertaAI receives webhook
  â”œâ”€ Creates SignalEvent (github_pr)
  â”œâ”€ Creates DriftCandidate (state=INGESTED)
  â””â”€ Enqueues job

10:00:10 AM - State machine runs (Job 1)
  â”œâ”€ INGESTED â†’ ELIGIBILITY_CHECKED (passes: touches deploy/)
  â”œâ”€ ELIGIBILITY_CHECKED â†’ SIGNALS_CORRELATED (no duplicates, no temporal bundle pending)
  â”œâ”€ SIGNALS_CORRELATED â†’ DOCS_RESOLVED (mapping: repo=acme/api â†’ doc=164013)
  â”œâ”€ DOCS_RESOLVED â†’ DOCS_FETCHED (fetches Confluence page 164013)
  â””â”€ Context expansion: fetches deploy/helm/values.yaml (full content, 2.1K chars)

10:00:15 AM - State machine runs (Job 2)
  â”œâ”€ DOCS_FETCHED â†’ DOC_CONTEXT_EXTRACTED (extracts "Deployment" section)
  â”œâ”€ DOC_CONTEXT_EXTRACTED â†’ EVIDENCE_EXTRACTED
  â”‚   Typed deltas generated:
  â”‚     [1] {artifactType: "tool", action: "changed", sourceValue: "helm", docValue: "kubectl", confidence: 0.95}
  â”‚     [2] {artifactType: "command", action: "removed", sourceValue: "kubectl apply -f k8s/deployment.yaml", confidence: 0.92}
  â”‚     [3] {artifactType: "command", action: "added", sourceValue: "helm install api-service ./chart", confidence: 0.92}
  â”œâ”€ EVIDENCE_EXTRACTED â†’ BASELINE_CHECKED
  â”‚   EvidenceBundle built: impactBand=high, 3 typed deltas
  â”‚   Threshold routing: confidence 0.92 > ignore 0.20 â†’ PASS
  â”‚   Materiality gate: impactBand=high, 3 deltas â†’ MATERIAL (no skip)
  â”œâ”€ BASELINE_CHECKED â†’ PATCH_PLANNED
  â”‚   LLM receives typed deltas (not raw diff): tool replacement kubectlâ†’helm + 2 command changes
  â””â”€ PATCH_PLANNED â†’ PATCH_GENERATED (LLM: generates evidence-grounded diff)

10:00:25 AM - State machine runs (Job 3)
  â”œâ”€ PATCH_GENERATED â†’ PATCH_VALIDATED (passes: no secrets, 8 lines, applies cleanly)
  â”œâ”€ PATCH_VALIDATED â†’ OWNER_RESOLVED (CODEOWNERS: @platform-team)
  â”œâ”€ OWNER_RESOLVED â†’ SLACK_SENT (sends to #platform-team)
  â””â”€ SLACK_SENT â†’ AWAITING_HUMAN

10:00:30 AM - Slack message appears in #platform-team
```

**Slack message:**

```
ğŸ”„ Documentation Drift Detected

Source: PR #1234 - "Migrate deployment from kubectl to helm"
Repo: acme/api-service
Doc: Deployment Runbook (Confluence)
Confidence: 92%

Proposed changes (8 lines):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
--- a/deployment-runbook.md
+++ b/deployment-runbook.md
@@ -15,7 +15,7 @@
 ## Deploy to Production

 1. Merge PR to `main`
-2. Run: `kubectl apply -f k8s/deployment.yaml`
+2. Run: `helm install api-service ./chart`
 3. Verify pods are running: `kubectl get pods`
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[Approve] [Edit] [Reject] [Snooze 24h]
```

**10:05 AM - Platform engineer clicks "Approve"**

```
10:05:00 AM - Slack interaction received
  â”œâ”€ Updates PatchProposal.status = 'approved'
  â”œâ”€ Updates DriftCandidate.state = APPROVED
  â””â”€ Enqueues job

10:05:05 AM - State machine runs (Job 4)
  â”œâ”€ APPROVED â†’ WRITEBACK_VALIDATED (checks Confluence page version)
  â”œâ”€ WRITEBACK_VALIDATED â†’ WRITTEN_BACK (applies diff via Confluence API)
  â””â”€ WRITTEN_BACK â†’ COMPLETED

10:05:10 AM - Slack message updates
  âœ… Approved and applied by @alice
  View updated doc: https://acme.atlassian.net/wiki/spaces/ENG/pages/164013
```

**Result:** Confluence page updated, deployment runbook now shows correct Helm command

---

### Example 3: PagerDuty Incident â†’ Confluence Runbook Update (Track 2)

**Scenario:** Production incident reveals new failure mode that should be documented

**Timeline:**

```
3:00 PM - Incident P-456 triggered (API Gateway 503 errors)
  â”œâ”€ Service: api-service
  â”œâ”€ Severity: high
  â””â”€ On-call: @bob

3:45 PM - Incident resolved
  â”œâ”€ Root cause: Redis connection pool exhausted
  â”œâ”€ Fix: Increased pool size from 10 to 50
  â”œâ”€ Resolution notes: "Added connection pool monitoring, updated config"
  â””â”€ PagerDuty webhook fires (incident.resolved)

3:45:05 PM - VertaAI receives webhook
  â”œâ”€ Creates SignalEvent (pagerduty_incident)
  â”œâ”€ Creates DriftCandidate (state=INGESTED)
  â””â”€ Enqueues job

3:45:10 PM - State machine processes
  â”œâ”€ INGESTED â†’ ELIGIBILITY_CHECKED (passes: has resolution notes)
  â”œâ”€ ELIGIBILITY_CHECKED â†’ SIGNALS_CORRELATED (no duplicates)
  â”œâ”€ SIGNALS_CORRELATED â†’ DOCS_RESOLVED (mapping: service=api-service â†’ doc=164013)
  â”œâ”€ DOCS_RESOLVED â†’ DOCS_FETCHED (fetches Confluence runbook)
  â”œâ”€ DOCS_FETCHED â†’ DOC_CONTEXT_EXTRACTED (extracts "Troubleshooting" section)
  â”œâ”€ DOC_CONTEXT_EXTRACTED â†’ EVIDENCE_EXTRACTED
  â”‚   Coverage gap detected: "Redis connection pool" not mentioned in runbook
  â”œâ”€ EVIDENCE_EXTRACTED â†’ BASELINE_CHECKED
  â”‚   driftType: "coverage", hasCoverageGap: true, confidence: 0.78
  â”œâ”€ BASELINE_CHECKED â†’ PATCH_PLANNED (LLM: plan new troubleshooting section)
  â”œâ”€ PATCH_PLANNED â†’ PATCH_GENERATED (LLM: generates diff with new section)
  â”œâ”€ PATCH_GENERATED â†’ PATCH_VALIDATED (passes: no secrets, size OK)
  â”œâ”€ PATCH_VALIDATED â†’ OWNER_RESOLVED (routes to @bob, on-call engineer)
  â””â”€ OWNER_RESOLVED â†’ SLACK_SENT

3:45:30 PM - Slack message sent to @bob
  ğŸ“Š Coverage Gap Detected

  Source: Incident P-456 (API Gateway 503 errors)
  Service: api-service
  Confidence: 78%

  Proposed change: Add new troubleshooting section for Redis connection pool issues

  [Approve] [Edit] [Reject] [Snooze 24h]

3:50 PM - @bob clicks "Approve"
  â”œâ”€ AWAITING_HUMAN â†’ APPROVED â†’ WRITEBACK_VALIDATED
  â”œâ”€ Fetches current Confluence page version
  â”œâ”€ Applies diff (adds new "Redis Connection Pool Issues" section)
  â””â”€ Updates Confluence page with comment: "Updated by VertaAI from Incident P-456"

3:50:05 PM - Confluence page updated
  âœ… New troubleshooting section added
  âœ… Future incidents will have documented resolution steps
```

**Result:** Runbook now includes new failure mode, preventing future confusion

---

### Example 4: Agent PR Gatekeeper â†’ Risk Assessment & GitHub Check (Cross-Cutting)

**Scenario:** Agent-authored PR touches deployment infrastructure without required evidence

**Timeline:**

```
10:00 AM - Developer opens PR #5678 (authored by GitHub Copilot)
  â”œâ”€ Title: "Update deployment configuration"
  â”œâ”€ Author: developer-name (but commit messages show Copilot markers)
  â”œâ”€ Files changed: terraform/eks.tf, deploy/helm/values.yaml
  â”œâ”€ Lines changed: 450 additions, 120 deletions
  â””â”€ GitHub webhook fires (pull_request.opened)

10:00:05 AM - VertaAI receives webhook
  â”œâ”€ Gatekeeper enabled (feature flag check)
  â”œâ”€ Runs agent detection heuristics
  â””â”€ Runs risk assessment

10:00:10 AM - Agent Detection Results
  â”œâ”€ Commit messages: Found "Co-authored-by: GitHub Copilot" (weight: 0.40)
  â”œâ”€ PR size: 570 lines (weight: 0.20)
  â”œâ”€ Tool signatures: Found "# Generated by" in code (weight: 0.15)
  â””â”€ Agent confidence: 75%

10:00:12 AM - Domain Detection
  â”œâ”€ IaC files detected: terraform/eks.tf
  â”œâ”€ Deployment files detected: deploy/helm/values.yaml
  â””â”€ High-risk domains: deployment, iac

10:00:14 AM - Evidence Check
  â”œâ”€ Tests changed: âŒ No test files modified
  â”œâ”€ "No tests needed" note: âŒ Not found in PR body
  â”œâ”€ Rollback procedure: âŒ Not found in PR body
  â”œâ”€ Deployment runbook link: âŒ Not found in PR body
  â””â”€ Missing evidence: 4 items

10:00:16 AM - Delta Sync Analysis
  â”œâ”€ IaC Parser: Detects EKS cluster configuration change
  â”‚   â””â”€ Finding: [CRITICAL] Deployment infrastructure change
  â”œâ”€ API Parser: No OpenAPI changes detected
  â””â”€ CODEOWNERS Parser: No ownership changes detected

10:00:18 AM - Impact Assessment
  â”œâ”€ Source Evidence: 450 lines added, 120 removed, deployment files
  â”œâ”€ Target Evidence: Runbook surface (deployment domain)
  â”œâ”€ Rules fired: "iac_change_high_impact", "deployment_config_change"
  â””â”€ Impact: score=0.75, band=high

10:00:20 AM - Signal Correlation
  â”œâ”€ Signal ID: github_pr_acme_api-service_5678
  â”œâ”€ Service inferred: api-service
  â”œâ”€ Correlation window: 7 days
  â”œâ”€ Found: 2 incidents (INC-789, INC-790) for api-service
  â””â”€ Correlated signals: 2

10:00:22 AM - Risk Tier Calculation
  â”œâ”€ Agent confidence: 75% Ã— 0.30 = 22.5%
  â”œâ”€ High-risk domains: 2 domains Ã— 0.25 = 50% (capped)
  â”œâ”€ Missing evidence: 4 items Ã— 0.15 = 60% â†’ 45% (capped)
  â”œâ”€ Impact score: 0.75 Ã— 0.20 = 15%
  â”œâ”€ Correlated incidents: 2 Ã— 0.10 = 20%
  â””â”€ Total risk score: 22.5 + 50 + 45 + 15 + 20 = 152.5% â†’ capped at 100%
      Final risk tier: BLOCK (â‰¥80%)

10:00:25 AM - GitHub Check Created
  â””â”€ Status: âŒ failure (BLOCK tier)
```

**GitHub Check Output:**

```
VertaAI Agent PR Gatekeeper
Status: âŒ BLOCK (Risk: 100%)

Summary:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Agent Confidence: 75% (likely agent-authored)
Impact Band: ğŸ”´ critical
Correlated Signals: 2 incidents in past 7 days
Delta Sync Findings: 1 critical

Missing Evidence (4):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âŒ Tests changed OR "no tests needed" note
âŒ Rollback procedure
âŒ Deployment runbook link
âŒ Migration note

High-Risk Domains (2):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸ deployment
âš ï¸ iac

Delta Sync Findings (1):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. [CRITICAL] IaC drift: Deployment infrastructure change detected
   File: terraform/eks.tf
   Suggested docs: deployment runbook, migration guide

Correlated Signals:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ INC-789 - API service outage (2 days ago)
â€¢ INC-790 - Deployment failure (5 days ago)

Suggested Actions:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Add tests for infrastructure changes OR add "no tests needed" note to PR description
2. Add rollback procedure to PR description
3. Add link to deployment runbook
4. Review correlated incidents: INC-789, INC-790
5. Consider breaking this PR into smaller, reviewable chunks
```

**Annotations on terraform/eks.tf:**
```
Line 45-60: [FAILURE] IaC drift: Deployment infrastructure change detected
Suggested docs: deployment runbook, migration guide
```

**10:05 AM - Developer updates PR**
  â”œâ”€ Adds rollback procedure to PR description
  â”œâ”€ Adds deployment runbook link
  â”œâ”€ Adds "no tests needed" note (infrastructure-only change)
  â”œâ”€ Adds migration note
  â””â”€ GitHub webhook fires (pull_request.synchronize)

**10:05:30 AM - VertaAI re-runs gatekeeper**
  â”œâ”€ Evidence check: All items now present âœ…
  â”œâ”€ Risk score recalculated: 22.5 + 50 + 0 + 15 + 20 = 107.5% â†’ capped at 100%
  â”‚   (Missing evidence now 0%, but still BLOCK due to other factors)
  â””â”€ GitHub Check updated: Still BLOCK (high impact + correlated incidents)

**10:10 AM - Platform team reviews**
  â”œâ”€ Sees evidence is complete
  â”œâ”€ Reviews correlated incidents
  â”œâ”€ Approves PR with manual override
  â””â”€ PR merged

**Result:** High-risk agent PR was properly gated, required evidence was added, and platform team made informed decision

---

### Example 3: PagerDuty Incident â†’ Ownership Doc Update

**Scenario:** Incident reveals team ownership changed

**Timeline:**

```
2:00 PM - PagerDuty incident P-12345 resolved
  â”œâ”€ Service: api-service
  â”œâ”€ Resolved by: bob (from new team @platform-team)
  â”œâ”€ Notes: "API gateway issue. Note: This service is now owned by platform team, not backend team."
  â””â”€ PagerDuty webhook fires

2:00:05 PM - VertaAI receives webhook
  â”œâ”€ Creates SignalEvent (pagerduty_incident)
  â”œâ”€ Creates DriftCandidate (state=INGESTED)
  â””â”€ Enqueues job

2:00:10 PM - State machine runs
  â”œâ”€ INGESTED â†’ ELIGIBILITY_CHECKED (passes: has resolution notes)
  â”œâ”€ ... (similar flow)
  â”œâ”€ DRIFT_CLASSIFIED (LLM: "ownership drift")
  â”œâ”€ DOCS_RESOLVED (mapping: service=api-service â†’ doc=165000 "Team Ownership")
  â”œâ”€ BASELINE_CHECKED (finds "@backend-team" in doc)
  â”œâ”€ PATCH_GENERATED (LLM: generates diff to change team)
  â””â”€ SLACK_SENT (sends to #platform-team)

2:00:30 PM - Slack message appears
```

**Slack message:**

```
ğŸ‘¥ Ownership Drift Detected

Source: PagerDuty Incident P-12345 - "API Gateway 503 errors"
Service: api-service
Doc: Team Ownership (Confluence)
Confidence: 85%

Proposed changes (4 lines):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
--- a/team-ownership.md
+++ b/team-ownership.md
@@ -10,7 +10,7 @@
 ## API Service

-Owner: @backend-team
+Owner: @platform-team
 Slack: #platform-team
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[Approve] [Edit] [Reject] [Snooze 24h]
```

**2:05 PM - Team lead clicks "Approve"**

**Result:** Ownership doc updated, future incidents will route to correct team

---

### Example 3: Multiple Signals Correlated â†’ Single Patch

**Scenario:** Two PRs in same repo change related deployment steps

**Timeline:**

```
9:00 AM - PR #1234 merged (adds Helm chart)
9:05 AM - PR #1235 merged (removes old kubectl files)

9:05:10 AM - VertaAI processes both signals
  â”œâ”€ Signal 1: PR #1234 (adds helm)
  â”œâ”€ Signal 2: PR #1235 (removes kubectl)
  â”œâ”€ Fingerprint match: Both affect "deployment" in same repo
  â””â”€ Correlation: Join signals into single DriftCandidate

9:05:15 AM - State machine runs
  â”œâ”€ SIGNALS_CORRELATED (2 signals joined)
  â”œâ”€ Evidence pack includes both PRs
  â”œâ”€ Patch generation uses combined context
  â””â”€ Single Slack message sent (references both PRs)
```

**Slack message:**

```
ğŸ”„ Documentation Drift Detected

Sources:
  â€¢ PR #1234 - "Add Helm chart"
  â€¢ PR #1235 - "Remove kubectl deployment files"

Repo: acme/api-service
Doc: Deployment Runbook (Confluence)
Confidence: 95%

Proposed changes (12 lines):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[Combined diff from both PRs]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[Approve] [Edit] [Reject] [Snooze 24h]
```

**Result:** One approval updates doc with changes from both PRs

---

## FAQ

### General Questions

**Q: What happens if I reject a patch?**

A: The drift is marked as REJECTED and stored with your feedback. We use rejection reasons to improve future classifications. The doc is not updated.

**Q: Can I edit the diff before approving?**

A: Yes! Click "Edit" in Slack, modify the diff, then click "Approve" on the updated version. The state machine will re-validate the edited diff.

**Q: How does VertaAI prevent hallucinations?**

A: Multiple layers:
1. **Evidence-grounded patching** - LLM agents receive structured typed deltas from the EvidenceBundle, not raw text. Every element in the prompt is backed by deterministic evidence
2. **Typed deltas as source of truth** - The LLM can only reference artifacts that appear in the typed deltas (commands, config keys, endpoints, tools, versions). It cannot invent new content
3. **Materiality gate** - Deterministic pre-patch filter prevents low-value, ambiguous drifts from reaching the LLM at all
4. **Baseline checking** - Only propose changes if we find exact evidence in the signal
5. **Diff-only output** - LLM can't rewrite entire docs, only generate diffs
6. **Validation layer** - Code checks for secrets, size limits, scope violations
7. **Human approval** - You always review before publishing
8. **Evidence trail** - Every change links back to source signal with full typed delta provenance

**Q: What if the wrong doc is selected?**

A: You can:
1. Click "Reject" and add feedback
2. Update the doc mapping in Settings â†’ Doc Mappings
3. Re-trigger the drift (Settings â†’ Test â†’ Re-process Drift)

**Q: How do I configure which repos to monitor?**

A: During GitHub OAuth, select which repos to install the VertaAI GitHub App on. You can add/remove repos anytime in GitHub Settings â†’ Applications â†’ VertaAI.

**Q: What's the difference between direct writeback and PR workflow?**

A:
- **Direct writeback** (Confluence, Notion): Clicking "Approve" immediately updates the doc via API
- **PR workflow** (README, Backstage, GitBook, Swagger): Clicking "Approve" creates a GitHub PR that you must manually review and merge

**Q: Can VertaAI auto-approve low-risk changes?**

A: Technically yes (set `autoApproveLowRisk: true` in workspace settings), but we **strongly recommend against it**. Human review catches edge cases and builds trust.

**Q: How much does it cost?**

A: Pricing is based on:
- Number of active repos monitored
- Number of drift notifications sent per month
- LLM API costs (passed through at cost)

Contact sales for pricing details.

---

### Technical Questions

**Q: What happens if the doc is updated between baseline fetch and writeback?**

A: **Optimistic locking** - We check the doc version before writing. If it changed, we:
1. Log a warning
2. Use the current version (not the baseline version)
3. Proceed with writeback

This prevents version conflicts while allowing updates to proceed.

**Q: How do you handle rate limits (GitHub, Confluence, Anthropic)?**

A: Exponential backoff with retries:
- Retry 1: Wait 2 seconds
- Retry 2: Wait 4 seconds
- Retry 3: Wait 8 seconds
- After 3 retries: Mark as FAILED with code RATE_LIMITED

**Q: Can I run VertaAI on-premise?**

A: Not currently. VertaAI is SaaS-only. We use Vercel (frontend) and Railway (backend) for hosting.

**Q: How do you secure OAuth tokens?**

A:
- Stored encrypted in PostgreSQL
- Never logged or exposed in API responses
- Rotated automatically when possible
- Scoped to minimum required permissions

**Q: What's the latency from PR merge to Slack notification?**

A: Typically **30-60 seconds**:
- Webhook delivery: ~1-2 seconds
- State machine processing: ~20-40 seconds (depends on LLM API latency)
- Slack API call: ~1-2 seconds

**Q: Can I use VertaAI with GitHub Enterprise?**

A: Yes! Configure the GitHub Enterprise URL in Settings â†’ Integrations â†’ GitHub â†’ Advanced.

**Q: How do you handle multi-region deployments?**

A: Currently single-region (US). Multi-region support planned for Q3 2026.

**Q: Can I export drift history?**

A: Yes! Dashboard â†’ Analytics â†’ Export â†’ CSV/JSON. Includes all drifts, approvals, rejections, and timestamps.

---

### Troubleshooting

**Q: Why am I not receiving Slack notifications?**

A: Check:
1. Slack app is installed (Settings â†’ Integrations â†’ Slack â†’ Status)
2. Default Slack channel is configured (Settings â†’ Workspace â†’ Default Slack Channel)
3. Confidence threshold isn't too high (Settings â†’ Workspace â†’ Confidence Threshold)
4. Rate limit not exceeded (Dashboard â†’ Analytics â†’ Notification Rate)
5. Railway logs for errors (contact support for access)

**Q: Why is my PR not triggering drift detection?**

A: Check:
1. PR is **merged** (not just opened)
2. PR touches operational paths (deploy/, infra/, etc.) - see Eligibility Rules
3. PR doesn't have excluded labels (skip-vertaai, docs-only)
4. PR author isn't excluded (dependabot, renovate)
5. GitHub webhook is active (Settings â†’ Integrations â†’ GitHub â†’ Webhook Status)

**Q: Why did the writeback fail?**

A: Common causes:
1. **Version conflict** - Doc was updated since baseline fetch (check logs)
2. **Permission denied** - OAuth token expired or lacks write permission
3. **Doc not found** - Doc ID is wrong or doc was deleted
4. **Validation failed** - Diff contains secrets, too large, or doesn't apply cleanly

Check Railway logs for specific error code.

**Q: How do I debug a specific drift?**

A:
1. Dashboard â†’ Drifts â†’ Search by ID
2. View state timeline (shows all state transitions)
3. View logs (shows LLM prompts, responses, errors)
4. Re-run state machine (Settings â†’ Test â†’ Re-process Drift)

---

## Support & Resources

- **Documentation:** https://docs.vertaai.com
- **Status Page:** https://status.vertaai.com
- **Support Email:** support@vertaai.com
- **Slack Community:** https://vertaai-community.slack.com
- **GitHub Issues:** https://github.com/vertaai/feedback

---

**Last Updated:** February 12, 2026
**Version:** 3.0
**Maintained by:** VertaAI Team

**Recent Updates (v3.0 â€” Evidence-Grounded Patching System)**:
- **Phase 1**: Typed deltas in ComparisonResult (key:value comparison, tool replacement detection, version mismatch detection)
- **Phase 2**: Wired EvidenceBundle to LLM agents (structured evidence contract replaces raw diff, truncation priority order)
- **Phase 3**: Materiality gate (deterministic pre-patch filter, skip reason tracking for temporal accumulation)
- **Phase 4**: Bounded context expansion (fetch up to 3 key files, 30K char budget, richer artifact extraction)
- **Phase 5**: Temporal drift accumulation (bundle small drifts over time, configurable windows and thresholds)
- Added sections 10-12: Typed Deltas & Evidence-Grounded Patching, Bounded Context Expansion, Temporal Drift Accumulation
- Updated Early Threshold Routing section with materiality gate (now section 8)
- Updated EvidenceBundle pattern with typed deltas and assessment model
- Updated state machine flow with materiality gate, typed deltas, bounded context expansion
- Updated Example 1 timeline with typed delta generation and evidence-grounded patching
- Updated FAQ anti-hallucination answer with evidence-grounding layers

**Previous Updates (v2.0)**:
- Added orthogonal coverage detection explanation
- Updated state machine flow with early threshold routing and clustering
- Added Evidence-Based Detection section (EvidenceBundle pattern)
- Added Audit Trail & Compliance section
- Added Early Threshold Routing section
- Added Cluster-First Drift Triage section
- Updated all drift type descriptions
- Reflected current system health (85%) and acceptance criteria (5/5)

